{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-04 12:15:57.967860: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-04 12:17:36.690488: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-12-04 12:17:36.779605: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-12-04 12:17:36.779971: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Root label (source = ASRS coding forms) : order = by descending frequency\n",
    "anomaly_labels=['Deviation / Discrepancy - Procedural',\n",
    "                    'Aircraft Equipment',\n",
    "                    'Conflict',\n",
    "                    'Inflight Event / Encounter',\n",
    "                    'ATC Issue',\n",
    "                    'Deviation - Altitude',\n",
    "                    'Deviation - Track / Heading',\n",
    "                    'Ground Event / Encounter',\n",
    "                    'Flight Deck / Cabin / Aircraft Event',\n",
    "                    'Ground Incursion',\n",
    "                    'Airspace Violation',\n",
    "                    'Deviation - Speed',\n",
    "                    'Ground Excursion',\n",
    "                    'No Specific Anomaly Occurred']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(path, labels, add_other=False):\n",
    "    loaded_data = pd.read_pickle(path)[0]\n",
    "\n",
    "    # Drop Anomaly NaN's\n",
    "    loaded_data = loaded_data.dropna(subset=['Anomaly']).reset_index(drop=True)\n",
    "\n",
    "    # Convert the 'Anomaly' column to a list of lists\n",
    "    anomaly_series = loaded_data['Anomaly']\n",
    "    anomaly_list = anomaly_series.str.split(';').apply(lambda x: [item.strip() for item in x])\n",
    "\n",
    "    # Initialize a DataFrame to hold the one-hot-encoded anomalies\n",
    "    anomaly_df = pd.DataFrame(index=loaded_data.index)\n",
    "\n",
    "    # Populate the DataFrame with one-hot-encoded columns for each prefix\n",
    "    for prefix in labels:\n",
    "        anomaly_df[prefix] = anomaly_list.apply(lambda anomalies: any(anomaly.startswith(prefix) for anomaly in anomalies)).astype(int)\n",
    "\n",
    "    # Add the 'Other' category\n",
    "    if add_other:\n",
    "        anomaly_df['Other'] = (anomaly_df.sum(axis=1) == 0).astype(int)\n",
    "\n",
    "    # Assign the one-hot-encoded anomalies as a new column 'labels' to 'loaded_data'\n",
    "    loaded_data['labels'] = anomaly_df.apply(lambda row: row.tolist(), axis=1)\n",
    "\n",
    "    # Now, 'loaded_data' is a DataFrame that includes both the 'text' and 'labels' columns\n",
    "    loaded_data['text'] = loaded_data[\"Narrative\"]\n",
    "\n",
    "    # If you want to create a new DataFrame with just 'text' and 'labels':\n",
    "    final_df = loaded_data[['text', 'labels']]\n",
    "    return final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I was the pilot flying performing the takeoff....</td>\n",
       "      <td>[1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>We had 6 shipments of dry ice for the flight; ...</td>\n",
       "      <td>[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I have seen a lot of mistakes on every flight ...</td>\n",
       "      <td>[1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>It was my first time flying into KEUG and I wa...</td>\n",
       "      <td>[0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I am writing this report to bring attention to...</td>\n",
       "      <td>[0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96981</th>\n",
       "      <td>WE WERE ENRTE IN LNAV AT FL310; 30 MI N OF ATL...</td>\n",
       "      <td>[1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96982</th>\n",
       "      <td>CLRED BY TWR CTL TO CROSS RWY 8R/26L AT TXWY E...</td>\n",
       "      <td>[0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96983</th>\n",
       "      <td>WHILE WORKING NUMEROUS CVG AND CMH DEPS AT A C...</td>\n",
       "      <td>[0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96984</th>\n",
       "      <td>ON MIDNIGHT SHIFT; APPROX XA00 LCL TIME; 2 SEC...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96985</th>\n",
       "      <td>I was working the FD/CD (Flight Data/Clearance...</td>\n",
       "      <td>[1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>96986 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  \\\n",
       "0      I was the pilot flying performing the takeoff....   \n",
       "1      We had 6 shipments of dry ice for the flight; ...   \n",
       "2      I have seen a lot of mistakes on every flight ...   \n",
       "3      It was my first time flying into KEUG and I wa...   \n",
       "4      I am writing this report to bring attention to...   \n",
       "...                                                  ...   \n",
       "96981  WE WERE ENRTE IN LNAV AT FL310; 30 MI N OF ATL...   \n",
       "96982  CLRED BY TWR CTL TO CROSS RWY 8R/26L AT TXWY E...   \n",
       "96983  WHILE WORKING NUMEROUS CVG AND CMH DEPS AT A C...   \n",
       "96984  ON MIDNIGHT SHIFT; APPROX XA00 LCL TIME; 2 SEC...   \n",
       "96985  I was working the FD/CD (Flight Data/Clearance...   \n",
       "\n",
       "                                           labels  \n",
       "0      [1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]  \n",
       "1      [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]  \n",
       "2      [1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0]  \n",
       "3      [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]  \n",
       "4      [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]  \n",
       "...                                           ...  \n",
       "96981  [1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]  \n",
       "96982  [0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0]  \n",
       "96983  [0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]  \n",
       "96984  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]  \n",
       "96985  [1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0]  \n",
       "\n",
       "[96986 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df_train = load_data(\"./data/train_data_final.pkl\", anomaly_labels)\n",
    "df_train\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Flying into SLC on the DELTA THREE RNAV arriva...</td>\n",
       "      <td>[1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ORD was on a very busy east flow arrival push....</td>\n",
       "      <td>[1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B737-800 was vectored to an ILS Runway 16L app...</td>\n",
       "      <td>[1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>We were on a 6 mile final when tower cleared a...</td>\n",
       "      <td>[1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>During Climb we Leveled at 17;000 departure sw...</td>\n",
       "      <td>[1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10800</th>\n",
       "      <td>FO was flying a visual approach to runway 26 i...</td>\n",
       "      <td>[1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10801</th>\n",
       "      <td>While assembling a GE C2 transfer gearbox; I n...</td>\n",
       "      <td>[1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10802</th>\n",
       "      <td>Nearing the end of a hot; bumpy four-hour IFR ...</td>\n",
       "      <td>[1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10803</th>\n",
       "      <td>On approach gear went down and noticed yellow ...</td>\n",
       "      <td>[1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10804</th>\n",
       "      <td>Approximately 20 minutes into our Ferry Flight...</td>\n",
       "      <td>[0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10805 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  \\\n",
       "0      Flying into SLC on the DELTA THREE RNAV arriva...   \n",
       "1      ORD was on a very busy east flow arrival push....   \n",
       "2      B737-800 was vectored to an ILS Runway 16L app...   \n",
       "3      We were on a 6 mile final when tower cleared a...   \n",
       "4      During Climb we Leveled at 17;000 departure sw...   \n",
       "...                                                  ...   \n",
       "10800  FO was flying a visual approach to runway 26 i...   \n",
       "10801  While assembling a GE C2 transfer gearbox; I n...   \n",
       "10802  Nearing the end of a hot; bumpy four-hour IFR ...   \n",
       "10803  On approach gear went down and noticed yellow ...   \n",
       "10804  Approximately 20 minutes into our Ferry Flight...   \n",
       "\n",
       "                                           labels  \n",
       "0      [1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0]  \n",
       "1      [1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]  \n",
       "2      [1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]  \n",
       "3      [1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0]  \n",
       "4      [1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]  \n",
       "...                                           ...  \n",
       "10800  [1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]  \n",
       "10801  [1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]  \n",
       "10802  [1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]  \n",
       "10803  [1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]  \n",
       "10804  [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0]  \n",
       "\n",
       "[10805 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = load_data(\"./data/test_data_final.pkl\", anomaly_labels)\n",
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0]]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import Dataset, DatasetDict\n",
    "# use from_dict() and not from_pandas(); otherwise you get an extra key, smth litke '__index col__'\n",
    "train_dataset = Dataset.from_dict(df_train)\n",
    "# validation_dataset = Dataset.from_dict(df_valid)\n",
    "test_dataset = Dataset.from_dict(df_test)\n",
    "\n",
    "# inspect this object\n",
    "train_dataset['labels'][:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f28e712efd8407586f44a501c914df6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/96986 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e7e70f18634497fb22ac6ea39a521ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10805 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gonem/miniforge3/envs/ENSAI/lib/python3.8/site-packages/datasets/arrow_dataset.py:400: FutureWarning: The output of `to_tf_dataset` will change when a passing single element list for `labels` or `columns` in the next datasets version. To return a tuple structure rather than dict, pass a single string.\n",
      "Old behaviour: columns=['a'], labels=['labels'] -> (tf.Tensor, tf.Tensor)  \n",
      "             : columns='a', labels='labels' -> (tf.Tensor, tf.Tensor)  \n",
      "New behaviour: columns=['a'],labels=['labels'] -> ({'a': tf.Tensor}, {'labels': tf.Tensor})  \n",
      "             : columns='a', labels='labels' -> (tf.Tensor, tf.Tensor) \n",
      "  warnings.warn(\n",
      "2023-12-04 12:18:56.529974: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-12-04 12:18:56.533681: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-12-04 12:18:56.534247: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-12-04 12:18:56.534551: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-12-04 12:18:56.604313: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-12-04 12:18:56.604840: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-12-04 12:18:56.605087: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-12-04 12:18:56.605207: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 4279 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "# Specify the model name for tokenizer\n",
    "model_name = \"bert-base-uncased\" # or any other model you are using\n",
    "\n",
    "# Instantiate tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# Define a tokenization function with max_length of 200\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples['text'], padding='max_length', truncation=True, max_length=200)\n",
    "\n",
    "# Apply tokenization to your datasets\n",
    "tokenized_train_dataset = train_dataset.map(tokenize_function, batched=True)\n",
    "tokenized_test_dataset = test_dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "# Convert to TensorFlow datasets if using TensorFlow models\n",
    "batch_size = 32\n",
    "\n",
    "# Instantiate a data_collator\n",
    "from transformers import DefaultDataCollator\n",
    "data_collator = DefaultDataCollator(return_tensors=\"tf\")\n",
    "\n",
    "tf_train_dataset = tokenized_train_dataset.to_tf_dataset(\n",
    "    columns=[\"attention_mask\", \"input_ids\", \"token_type_ids\"],\n",
    "    label_cols=[\"labels\"],\n",
    "    shuffle=True,\n",
    "    collate_fn=data_collator,  # Defined earlier in your code\n",
    "    batch_size=batch_size\n",
    ")\n",
    "\n",
    "tf_test_dataset = tokenized_test_dataset.to_tf_dataset(\n",
    "    columns=[\"attention_mask\", \"input_ids\", \"token_type_ids\"],\n",
    "    label_cols=[\"labels\"],\n",
    "    shuffle=False,\n",
    "    collate_fn=data_collator,  # Defined earlier in your code\n",
    "    batch_size=batch_size\n",
    ")\n",
    "\n",
    "# Now, you can either train your model using tf_train_dataset or use it for inference.\n",
    "# For training:\n",
    "# model.fit(tf_train_dataset, validation_data=tf_validation_dataset, epochs=num_epochs)\n",
    "\n",
    "# For inference:\n",
    "# predictions = model.predict(tf_test_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the path to your saved model directory\n",
    "model_directory = 'model_save/7_6_1_UNfrozen_2022_09_14'\n",
    "\n",
    "# Load the model\n",
    "loaded_model = tf.keras.models.load_model(model_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-04 12:20:10.633958: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:630] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "338/338 [==============================] - 95s 277ms/step - loss: 0.1720 - binary_accuracy: 0.9311\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.17195776104927063, 0.9310636520385742]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_model.evaluate(tf_test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ENSAI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
