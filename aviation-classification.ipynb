{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing stock ml libraries\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import metrics\n",
    "import transformers\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from transformers import BertTokenizer, BertModel, BertConfig, BertForSequenceClassification\n",
    "from transformers import AutoTokenizer, AutoModel, AutoModelForSequenceClassification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setting up the device for GPU usage\n",
    "from torch import cuda\n",
    "device = 'cuda' if cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Root label (source = ASRS coding forms) : order = by descending frequency\n",
    "ANOMALY_LABELS = ['Deviation / Discrepancy - Procedural',\n",
    "                    'Aircraft Equipment',\n",
    "                    'Conflict',\n",
    "                    'Inflight Event / Encounter',\n",
    "                    'ATC Issue',\n",
    "                    'Deviation - Altitude',\n",
    "                    'Deviation - Track / Heading',\n",
    "                    'Ground Event / Encounter',\n",
    "                    'Flight Deck / Cabin / Aircraft Event',\n",
    "                    'Ground Incursion',\n",
    "                    'Airspace Violation',\n",
    "                    'Deviation - Speed',\n",
    "                    'Ground Excursion',\n",
    "                    'No Specific Anomaly Occurred']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(path, labels, add_other=False, pp_path=None):\n",
    "    loaded_data = pd.read_pickle(path)[0]\n",
    "\n",
    "    # Drop Anomaly NaN's\n",
    "    loaded_data = loaded_data.dropna(subset=['Anomaly'])#.reset_index(drop=True)\n",
    "\n",
    "    # Convert the 'Anomaly' column to a list of lists\n",
    "    anomaly_series = loaded_data['Anomaly']\n",
    "    anomaly_list = anomaly_series.str.split(';').apply(lambda x: [item.strip() for item in x])\n",
    "\n",
    "    # Initialize a DataFrame to hold the one-hot-encoded anomalies\n",
    "    anomaly_df = pd.DataFrame(index=loaded_data.index)\n",
    "\n",
    "    # Populate the DataFrame with one-hot-encoded columns for each prefix\n",
    "    for prefix in labels:\n",
    "        anomaly_df[prefix] = anomaly_list.apply(lambda anomalies: any(anomaly.startswith(prefix) for anomaly in anomalies)).astype(int)\n",
    "\n",
    "    # Add the 'Other' category\n",
    "    if add_other:\n",
    "        anomaly_df['Other'] = (anomaly_df.sum(axis=1) == 0).astype(int)\n",
    "\n",
    "    # Assign the one-hot-encoded anomalies as a new column 'labels' to 'loaded_data'\n",
    "    loaded_data['labels'] = anomaly_df.apply(lambda row: row.tolist(), axis=1)\n",
    "\n",
    "    # Now, 'loaded_data' is a DataFrame that includes both the 'text' and 'labels' columns\n",
    "    if pp_path is None:\n",
    "        loaded_data['text'] = loaded_data[\"Narrative\"]\n",
    "    else:\n",
    "        loaded_data['text'] = pd.read_pickle(pp_path)\n",
    "\n",
    "    # If you want to create a new DataFrame with just 'text' and 'labels':\n",
    "    final_df = loaded_data[['text', 'labels']]\n",
    "    return final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "drop the NaN values in Anomaly?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACN</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1163382</th>\n",
       "      <td>I pilot flying performing takeoff . During tak...</td>\n",
       "      <td>[1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>893734</th>\n",
       "      <td>We 6 shipments dry ice flight ; cooling fresh ...</td>\n",
       "      <td>[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>991883</th>\n",
       "      <td>I seen lot mistakes every flight since changed...</td>\n",
       "      <td>[1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1590076</th>\n",
       "      <td>It first time flying KEUG I pilot flying . The...</td>\n",
       "      <td>[0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1715282</th>\n",
       "      <td>I writing report bring attention second depart...</td>\n",
       "      <td>[0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>622204</th>\n",
       "      <td>WE WERE En Route IN Lateral Navigation AT FL31...</td>\n",
       "      <td>[1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>622205</th>\n",
       "      <td>CLRED BY Tower Control TO CROSS Runway 8R/26L ...</td>\n",
       "      <td>[0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>661202</th>\n",
       "      <td>WHILE WORKING NUMEROUS CVG AND CMH DEPS AT A C...</td>\n",
       "      <td>[0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>733747</th>\n",
       "      <td>ON MIDNIGHT SHIFT ; Approximately XA00 Local T...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>874642</th>\n",
       "      <td>I working FD/CD ( Flight Data/Clearance Delive...</td>\n",
       "      <td>[1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>96986 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      text  \\\n",
       "ACN                                                          \n",
       "1163382  I pilot flying performing takeoff . During tak...   \n",
       "893734   We 6 shipments dry ice flight ; cooling fresh ...   \n",
       "991883   I seen lot mistakes every flight since changed...   \n",
       "1590076  It first time flying KEUG I pilot flying . The...   \n",
       "1715282  I writing report bring attention second depart...   \n",
       "...                                                    ...   \n",
       "622204   WE WERE En Route IN Lateral Navigation AT FL31...   \n",
       "622205   CLRED BY Tower Control TO CROSS Runway 8R/26L ...   \n",
       "661202   WHILE WORKING NUMEROUS CVG AND CMH DEPS AT A C...   \n",
       "733747   ON MIDNIGHT SHIFT ; Approximately XA00 Local T...   \n",
       "874642   I working FD/CD ( Flight Data/Clearance Delive...   \n",
       "\n",
       "                                             labels  \n",
       "ACN                                                  \n",
       "1163382  [1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]  \n",
       "893734   [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]  \n",
       "991883   [1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0]  \n",
       "1590076  [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]  \n",
       "1715282  [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]  \n",
       "...                                             ...  \n",
       "622204   [1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]  \n",
       "622205   [0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0]  \n",
       "661202   [0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]  \n",
       "733747   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]  \n",
       "874642   [1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0]  \n",
       "\n",
       "[96986 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = load_data(\"./data/train_data_final.pkl\", ANOMALY_LABELS, pp_path=\"./data/train_data_processed2.pkl\")\n",
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACN</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1014798</th>\n",
       "      <td>Flying SLC DELTA THREE Area Navigation arrival...</td>\n",
       "      <td>[1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1806744</th>\n",
       "      <td>ORD busy east flow arrival push . The weather ...</td>\n",
       "      <td>[1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1044902</th>\n",
       "      <td>B737-800 vectored Instrument Landing System Ru...</td>\n",
       "      <td>[1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1764093</th>\n",
       "      <td>We 6 mile final tower cleared Cirrus land fron...</td>\n",
       "      <td>[1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1786435</th>\n",
       "      <td>During Climb Leveled 17 ; 000 departure switch...</td>\n",
       "      <td>[1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1310569</th>\n",
       "      <td>FO flying visual approach runway 26 ZZZ . Wind...</td>\n",
       "      <td>[1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1482118</th>\n",
       "      <td>While assembling GE C2 transfer gearbox ; I no...</td>\n",
       "      <td>[1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1565471</th>\n",
       "      <td>Nearing end hot ; bumpy four-hour Instrument F...</td>\n",
       "      <td>[1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>980316</th>\n",
       "      <td>On approach gear went noticed yellow hash mark...</td>\n",
       "      <td>[1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1269392</th>\n",
       "      <td>Approximately 20 minutes Ferry Flight landing ...</td>\n",
       "      <td>[0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10805 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      text  \\\n",
       "ACN                                                          \n",
       "1014798  Flying SLC DELTA THREE Area Navigation arrival...   \n",
       "1806744  ORD busy east flow arrival push . The weather ...   \n",
       "1044902  B737-800 vectored Instrument Landing System Ru...   \n",
       "1764093  We 6 mile final tower cleared Cirrus land fron...   \n",
       "1786435  During Climb Leveled 17 ; 000 departure switch...   \n",
       "...                                                    ...   \n",
       "1310569  FO flying visual approach runway 26 ZZZ . Wind...   \n",
       "1482118  While assembling GE C2 transfer gearbox ; I no...   \n",
       "1565471  Nearing end hot ; bumpy four-hour Instrument F...   \n",
       "980316   On approach gear went noticed yellow hash mark...   \n",
       "1269392  Approximately 20 minutes Ferry Flight landing ...   \n",
       "\n",
       "                                             labels  \n",
       "ACN                                                  \n",
       "1014798  [1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0]  \n",
       "1806744  [1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]  \n",
       "1044902  [1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]  \n",
       "1764093  [1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0]  \n",
       "1786435  [1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]  \n",
       "...                                             ...  \n",
       "1310569  [1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]  \n",
       "1482118  [1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]  \n",
       "1565471  [1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]  \n",
       "980316   [1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]  \n",
       "1269392  [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0]  \n",
       "\n",
       "[10805 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = load_data(\"./data/test_data_final.pkl\", ANOMALY_LABELS, pp_path=\"./data/test_data_processed2.pkl\")\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_df = load_data(\"./data/train_data_final.pkl\", ANOMALY_LABELS)\n",
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Flying into SLC on the DELTA THREE RNAV arriva...</td>\n",
       "      <td>[1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ORD was on a very busy east flow arrival push....</td>\n",
       "      <td>[1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B737-800 was vectored to an ILS Runway 16L app...</td>\n",
       "      <td>[1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>We were on a 6 mile final when tower cleared a...</td>\n",
       "      <td>[1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>During Climb we Leveled at 17;000 departure sw...</td>\n",
       "      <td>[1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10800</th>\n",
       "      <td>FO was flying a visual approach to runway 26 i...</td>\n",
       "      <td>[1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10801</th>\n",
       "      <td>While assembling a GE C2 transfer gearbox; I n...</td>\n",
       "      <td>[1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10802</th>\n",
       "      <td>Nearing the end of a hot; bumpy four-hour IFR ...</td>\n",
       "      <td>[1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10803</th>\n",
       "      <td>On approach gear went down and noticed yellow ...</td>\n",
       "      <td>[1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10804</th>\n",
       "      <td>Approximately 20 minutes into our Ferry Flight...</td>\n",
       "      <td>[0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10805 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  \\\n",
       "0      Flying into SLC on the DELTA THREE RNAV arriva...   \n",
       "1      ORD was on a very busy east flow arrival push....   \n",
       "2      B737-800 was vectored to an ILS Runway 16L app...   \n",
       "3      We were on a 6 mile final when tower cleared a...   \n",
       "4      During Climb we Leveled at 17;000 departure sw...   \n",
       "...                                                  ...   \n",
       "10800  FO was flying a visual approach to runway 26 i...   \n",
       "10801  While assembling a GE C2 transfer gearbox; I n...   \n",
       "10802  Nearing the end of a hot; bumpy four-hour IFR ...   \n",
       "10803  On approach gear went down and noticed yellow ...   \n",
       "10804  Approximately 20 minutes into our Ferry Flight...   \n",
       "\n",
       "                                           labels  \n",
       "0      [1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0]  \n",
       "1      [1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]  \n",
       "2      [1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]  \n",
       "3      [1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0]  \n",
       "4      [1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]  \n",
       "...                                           ...  \n",
       "10800  [1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]  \n",
       "10801  [1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]  \n",
       "10802  [1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]  \n",
       "10803  [1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]  \n",
       "10804  [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0]  \n",
       "\n",
       "[10805 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = load_data(\"./data/test_data_final.pkl\", ANOMALY_LABELS)\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "A Dataframe with 10824 entries has been loaded\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Local Time Of Day</th>\n",
       "      <th>Locale Reference</th>\n",
       "      <th>State Reference</th>\n",
       "      <th>Relative Position.Angle.Radial</th>\n",
       "      <th>Relative Position.Distance.Nautical Miles</th>\n",
       "      <th>Altitude.AGL.Single Value</th>\n",
       "      <th>Altitude.MSL.Single Value</th>\n",
       "      <th>Flight Conditions</th>\n",
       "      <th>Weather Elements / Visibility</th>\n",
       "      <th>...</th>\n",
       "      <th>Result</th>\n",
       "      <th>Contributing Factors / Situations</th>\n",
       "      <th>Primary Problem</th>\n",
       "      <th>Narrative</th>\n",
       "      <th>Callback</th>\n",
       "      <th>Narrative.1</th>\n",
       "      <th>Callback.1</th>\n",
       "      <th>Synopsis</th>\n",
       "      <th>Year</th>\n",
       "      <th>anomaly_encoding</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACN</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1014798</th>\n",
       "      <td>201206</td>\n",
       "      <td>0601-1200</td>\n",
       "      <td>SLC.Airport</td>\n",
       "      <td>UT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11300.0</td>\n",
       "      <td>VMC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>General None Reported / Taken</td>\n",
       "      <td>Aircraft; Human Factors</td>\n",
       "      <td>Aircraft</td>\n",
       "      <td>Flying into SLC on the DELTA THREE RNAV arriva...</td>\n",
       "      <td>The Reporter stated that his aircraft is equip...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A CE750 Captain noted that his aircraft's FMS ...</td>\n",
       "      <td>2012</td>\n",
       "      <td>[1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1806744</th>\n",
       "      <td>202105</td>\n",
       "      <td>1201-1800</td>\n",
       "      <td>ORD.Airport</td>\n",
       "      <td>IL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3900.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>Flight Crew FLC complied w / Automation / Advi...</td>\n",
       "      <td>Human Factors; Procedure; Airspace Structure; ...</td>\n",
       "      <td>Airspace Structure</td>\n",
       "      <td>ORD was on a very busy east flow arrival push....</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C90TRACON Controller reported they did not not...</td>\n",
       "      <td>2021</td>\n",
       "      <td>[1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1044902</th>\n",
       "      <td>201210</td>\n",
       "      <td>0001-0600</td>\n",
       "      <td>S46.TRACON</td>\n",
       "      <td>WA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>General None Reported / Taken</td>\n",
       "      <td>ATC Equipment / Nav Facility / Buildings</td>\n",
       "      <td>ATC Equipment / Nav Facility / Buildings</td>\n",
       "      <td>B737-800 was vectored to an ILS Runway 16L app...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S46 Controller expressed concern regarding the...</td>\n",
       "      <td>2012</td>\n",
       "      <td>[1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1764093</th>\n",
       "      <td>202009</td>\n",
       "      <td>0601-1200</td>\n",
       "      <td>ZZZ.Tower</td>\n",
       "      <td>US</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>400.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>VMC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>Flight Crew Executed Go Around / Missed Approach</td>\n",
       "      <td>Human Factors; Procedure</td>\n",
       "      <td>Human Factors</td>\n",
       "      <td>We were on a 6 mile final when tower cleared a...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>While on about a six mile final tower cleared ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CRJ-200 flight crew reported failing to retrac...</td>\n",
       "      <td>2020</td>\n",
       "      <td>[1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1786435</th>\n",
       "      <td>202102</td>\n",
       "      <td>1201-1800</td>\n",
       "      <td>ZZZ.ARTCC</td>\n",
       "      <td>US</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>Air Traffic Control Issued New Clearance; Flig...</td>\n",
       "      <td>Environment - Non Weather Related; Human Facto...</td>\n",
       "      <td>Environment - Non Weather Related</td>\n",
       "      <td>During Climb we Leveled at 17;000 departure sw...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>after copilot (pf) leved at 17000'; dfw depart...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Air carrier First Officer reported an altitude...</td>\n",
       "      <td>2021</td>\n",
       "      <td>[1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 97 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Date Local Time Of Day Locale Reference State Reference  \\\n",
       "ACN                                                                  \n",
       "1014798  201206         0601-1200      SLC.Airport              UT   \n",
       "1806744  202105         1201-1800      ORD.Airport              IL   \n",
       "1044902  201210         0001-0600       S46.TRACON              WA   \n",
       "1764093  202009         0601-1200        ZZZ.Tower              US   \n",
       "1786435  202102         1201-1800        ZZZ.ARTCC              US   \n",
       "\n",
       "         Relative Position.Angle.Radial  \\\n",
       "ACN                                       \n",
       "1014798                             NaN   \n",
       "1806744                             NaN   \n",
       "1044902                             NaN   \n",
       "1764093                             NaN   \n",
       "1786435                             NaN   \n",
       "\n",
       "         Relative Position.Distance.Nautical Miles Altitude.AGL.Single Value  \\\n",
       "ACN                                                                            \n",
       "1014798                                        NaN                       NaN   \n",
       "1806744                                        NaN                       NaN   \n",
       "1044902                                        NaN                       NaN   \n",
       "1764093                                        NaN                     400.0   \n",
       "1786435                                        NaN                       NaN   \n",
       "\n",
       "         Altitude.MSL.Single Value Flight Conditions  \\\n",
       "ACN                                                    \n",
       "1014798                    11300.0               VMC   \n",
       "1806744                     3900.0               NaN   \n",
       "1044902                        NaN               NaN   \n",
       "1764093                        NaN               VMC   \n",
       "1786435                    17000.0               NaN   \n",
       "\n",
       "        Weather Elements / Visibility  ...  \\\n",
       "ACN                                    ...   \n",
       "1014798                           NaN  ...   \n",
       "1806744                           NaN  ...   \n",
       "1044902                           NaN  ...   \n",
       "1764093                           NaN  ...   \n",
       "1786435                           NaN  ...   \n",
       "\n",
       "                                                    Result  \\\n",
       "ACN                                                          \n",
       "1014798                      General None Reported / Taken   \n",
       "1806744  Flight Crew FLC complied w / Automation / Advi...   \n",
       "1044902                      General None Reported / Taken   \n",
       "1764093   Flight Crew Executed Go Around / Missed Approach   \n",
       "1786435  Air Traffic Control Issued New Clearance; Flig...   \n",
       "\n",
       "                         Contributing Factors / Situations  \\\n",
       "ACN                                                          \n",
       "1014798                            Aircraft; Human Factors   \n",
       "1806744  Human Factors; Procedure; Airspace Structure; ...   \n",
       "1044902           ATC Equipment / Nav Facility / Buildings   \n",
       "1764093                           Human Factors; Procedure   \n",
       "1786435  Environment - Non Weather Related; Human Facto...   \n",
       "\n",
       "                                  Primary Problem  \\\n",
       "ACN                                                 \n",
       "1014798                                  Aircraft   \n",
       "1806744                        Airspace Structure   \n",
       "1044902  ATC Equipment / Nav Facility / Buildings   \n",
       "1764093                             Human Factors   \n",
       "1786435         Environment - Non Weather Related   \n",
       "\n",
       "                                                 Narrative  \\\n",
       "ACN                                                          \n",
       "1014798  Flying into SLC on the DELTA THREE RNAV arriva...   \n",
       "1806744  ORD was on a very busy east flow arrival push....   \n",
       "1044902  B737-800 was vectored to an ILS Runway 16L app...   \n",
       "1764093  We were on a 6 mile final when tower cleared a...   \n",
       "1786435  During Climb we Leveled at 17;000 departure sw...   \n",
       "\n",
       "                                                  Callback  \\\n",
       "ACN                                                          \n",
       "1014798  The Reporter stated that his aircraft is equip...   \n",
       "1806744                                                NaN   \n",
       "1044902                                                NaN   \n",
       "1764093                                                NaN   \n",
       "1786435                                                NaN   \n",
       "\n",
       "                                               Narrative.1 Callback.1  \\\n",
       "ACN                                                                     \n",
       "1014798                                                NaN        NaN   \n",
       "1806744                                                NaN        NaN   \n",
       "1044902                                                NaN        NaN   \n",
       "1764093  While on about a six mile final tower cleared ...        NaN   \n",
       "1786435  after copilot (pf) leved at 17000'; dfw depart...        NaN   \n",
       "\n",
       "                                                  Synopsis  Year  \\\n",
       "ACN                                                                \n",
       "1014798  A CE750 Captain noted that his aircraft's FMS ...  2012   \n",
       "1806744  C90TRACON Controller reported they did not not...  2021   \n",
       "1044902  S46 Controller expressed concern regarding the...  2012   \n",
       "1764093  CRJ-200 flight crew reported failing to retrac...  2020   \n",
       "1786435  Air carrier First Officer reported an altitude...  2021   \n",
       "\n",
       "                                      anomaly_encoding  \n",
       "ACN                                                     \n",
       "1014798  [1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]  \n",
       "1806744  [1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]  \n",
       "1044902  [1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]  \n",
       "1764093  [1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0]  \n",
       "1786435  [1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]  \n",
       "\n",
       "[5 rows x 97 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MODEL_NAME = None\n",
    "MODEL_DIRECTORY = \"model_save\"\n",
    "\n",
    "\n",
    "# Sections of configBertTokenizer\n",
    "# Defining some key variables that will be used later on in the training\n",
    "BALANCED = False\n",
    "LAYERS_TO_UNFREEZE = None\n",
    "# LAYERS_TO_UNFREEZE = [8, 9, 10, 11]\n",
    "\n",
    "MAX_LEN = 512\n",
    "# MAX_LEN = 1024\n",
    "\n",
    "TRAIN_EFFECTIVE_BATCH_SIZE = 32 # 32 Effective size for NASA\n",
    "TRAIN_BATCH_SIZE = 32\n",
    "ACCUMULATION_STEPS = TRAIN_EFFECTIVE_BATCH_SIZE / TRAIN_BATCH_SIZE\n",
    "VALID_BATCH_SIZE = TRAIN_BATCH_SIZE\n",
    "EPOCHS = 5 # 5 Epochs for NASA\n",
    "LEARNING_RATE = 1e-05 * 2 # 0.00002 Rate for NASA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# MODEL_NAME = \"model\"\n",
    "MODEL_NAME = None\n",
    "MODEL_DIRECTORY = \"model_save\"\n",
    "\n",
    "\n",
    "# Sections of configBertTokenizer\n",
    "# Defining some key variables that will be used later on in the training\n",
    "BALANCED = True\n",
    "# LAYERS_TO_UNFREEZE = None\n",
    "LAYERS_TO_UNFREEZE = [8, 9, 10, 11]\n",
    "\n",
    "MAX_LEN = 512\n",
    "TRAIN_BATCH_SIZE = 32 # 32 Size for NASA\n",
    "VALID_BATCH_SIZE = 32\n",
    "EPOCHS = 5 # 5 Epochs for NASA\n",
    "LEARNING_RATE = 1e-05 * 2 # 0.00002 Rate for NASA\n",
    "# tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"NASA-AIML/MIKA_SafeAeroBERT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "\n",
    "    def __init__(self, dataframe, tokenizer, max_len):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.data = dataframe\n",
    "        self.text = dataframe.text\n",
    "        self.targets = self.data.labels\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.text)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        text = str(self.text.iloc[index])\n",
    "        text = \" \".join(text.split())\n",
    "\n",
    "        inputs = self.tokenizer(\n",
    "            text,\n",
    "            None,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_token_type_ids=True\n",
    "        )\n",
    "        ids = inputs['input_ids']\n",
    "        mask = inputs['attention_mask']\n",
    "        token_type_ids = inputs[\"token_type_ids\"]\n",
    "\n",
    "\n",
    "        return {\n",
    "            'ids': torch.tensor(ids, dtype=torch.long),\n",
    "            'mask': torch.tensor(mask, dtype=torch.long),\n",
    "            'token_type_ids': torch.tensor(token_type_ids, dtype=torch.long),\n",
    "            'targets': torch.tensor(self.targets.iloc[index], dtype=torch.float)\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SequenceClassificationModel(\n",
       "  (l1): BertForSequenceClassification(\n",
       "    (bert): BertModel(\n",
       "      (embeddings): BertEmbeddings(\n",
       "        (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "        (position_embeddings): Embedding(512, 768)\n",
       "        (token_type_embeddings): Embedding(2, 768)\n",
       "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (encoder): BertEncoder(\n",
       "        (layer): ModuleList(\n",
       "          (0-11): 12 x BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (pooler): BertPooler(\n",
       "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (activation): Tanh()\n",
       "      )\n",
       "    )\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (classifier): Linear(in_features=768, out_features=14, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_labels = len(test_df.labels[0])\n",
    "\n",
    "model = SequenceClassificationModel('bert-base-uncased', num_labels=num_labels)\n",
    "# model = SequenceClassificationModel('NASA-AIML/MIKA_SafeAeroBERT', num_labels=num_labels)\n",
    "# model = SequenceClassificationModel('allenai/longformer-base-4096', num_labels=num_labels)\n",
    "\n",
    "model.set_trainable_layers(LAYERS_TO_UNFREEZE)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN Dataset: (96986, 2)\n",
      "TEST Dataset: (10805, 2)\n"
     ]
    }
   ],
   "source": [
    "# Creating the dataset and dataloader for the neural network\n",
    "print(\"TRAIN Dataset: {}\".format(train_df.shape))\n",
    "print(\"TEST Dataset: {}\".format(test_df.shape))\n",
    "\n",
    "tokenizer = model.tokenizer()\n",
    "training_set = CustomDataset(train_df, tokenizer, MAX_LEN)\n",
    "testing_set = CustomDataset(test_df, tokenizer, MAX_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_params = {'batch_size': TRAIN_BATCH_SIZE,\n",
    "                'shuffle': True,\n",
    "                'num_workers': 2\n",
    "                }\n",
    "\n",
    "test_params = {'batch_size': VALID_BATCH_SIZE,\n",
    "                'shuffle': False,\n",
    "                'num_workers': 2\n",
    "                }\n",
    "\n",
    "training_loader = DataLoader(training_set, **train_params)\n",
    "testing_loader = DataLoader(testing_set, **test_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at NASA-AIML/MIKA_SafeAeroBERT and are newly initialized: ['classifier.weight', 'bert.pooler.dense.weight', 'classifier.bias', 'bert.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BERTClass(\n",
       "  (l1): BertForSequenceClassification(\n",
       "    (bert): BertModel(\n",
       "      (embeddings): BertEmbeddings(\n",
       "        (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "        (position_embeddings): Embedding(512, 768)\n",
       "        (token_type_embeddings): Embedding(2, 768)\n",
       "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (encoder): BertEncoder(\n",
       "        (layer): ModuleList(\n",
       "          (0-11): 12 x BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (pooler): BertPooler(\n",
       "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (activation): Tanh()\n",
       "      )\n",
       "    )\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (classifier): Linear(in_features=768, out_features=15, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_labels = len(test_df.labels.iloc[0])\n",
    "\n",
    "# model = SequenceClassificationModel('bert-base-uncased', num_labels=num_labels)\n",
    "model = SequenceClassificationModel('NASA-AIML/MIKA_SafeAeroBERT', num_labels=num_labels)\n",
    "# model = SequenceClassificationModel('allenai/longformer-base-4096', num_labels=num_labels)\n",
    "\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at NASA-AIML/MIKA_SafeAeroBERT and are newly initialized: ['classifier.bias', 'bert.pooler.dense.weight', 'classifier.weight', 'bert.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SafeAeroBERTClass(\n",
       "  (l1): BertForSequenceClassification(\n",
       "    (bert): BertModel(\n",
       "      (embeddings): BertEmbeddings(\n",
       "        (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "        (position_embeddings): Embedding(512, 768)\n",
       "        (token_type_embeddings): Embedding(2, 768)\n",
       "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (encoder): BertEncoder(\n",
       "        (layer): ModuleList(\n",
       "          (0-11): 12 x BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (pooler): BertPooler(\n",
       "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (activation): Tanh()\n",
       "      )\n",
       "    )\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (classifier): Linear(in_features=768, out_features=15, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class SafeAeroBERTClass(torch.nn.Module):\n",
    "    def __init__(self, num_labels=15):\n",
    "        super(SafeAeroBERTClass, self).__init__()\n",
    "        self.l1 = AutoModelForSequenceClassification.from_pretrained(\"NASA-AIML/MIKA_SafeAeroBERT\", num_labels=num_labels,)\n",
    "\n",
    "    def forward(self, ids, mask, token_type_ids):\n",
    "        output = self.l1(ids, attention_mask=mask, token_type_ids=token_type_ids)\n",
    "        return output.logits\n",
    "\n",
    "model = SafeAeroBERTClass()\n",
    "\n",
    "# Freeze all layers in the model\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Unfreeze the classifier and pooler layers\n",
    "for param in model.l1.classifier.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "for param in model.l1.bert.pooler.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_params = {'batch_size': TRAIN_BATCH_SIZE,\n",
    "                'shuffle': True,\n",
    "                'num_workers': 2\n",
    "                }\n",
    "\n",
    "test_params = {'batch_size': VALID_BATCH_SIZE,\n",
    "                'shuffle': False,\n",
    "                'num_workers': 2\n",
    "                }\n",
    "\n",
    "training_loader = DataLoader(training_set, **train_params)\n",
    "testing_loader = DataLoader(testing_set, **test_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_accuracy_per_label(y_true, y_pred):\n",
    "    correct = y_pred == y_true\n",
    "    accuracy_per_label = correct.float().mean(axis=0)\n",
    "    return accuracy_per_label\n",
    "\n",
    "def binary_accuracy_averaged(y_true, y_pred):\n",
    "    accuracy_per_label = binary_accuracy_per_label(y_true, y_pred)\n",
    "    accuracy_averaged = accuracy_per_label.mean()\n",
    "    return accuracy_averaged\n",
    "\n",
    "def custom_classification_report(y_true, y_pred):\n",
    "    report = metrics.classification_report(y_true, y_pred, output_dict=True, target_names=ANOMALY_LABELS, zero_division=0)\n",
    "    accuracy = binary_accuracy_per_label(y_true, y_pred)\n",
    "    extended_accuracy_new = np.append(accuracy, [accuracy.mean()] * (len(report) - len(accuracy)))\n",
    "\n",
    "    updated_report = {}\n",
    "    for i, class_label in enumerate(report.keys()):\n",
    "        # Create a new dictionary for the class with binary accuracy\n",
    "        class_dict = {'binary_accuracy': extended_accuracy_new[i]}\n",
    "        \n",
    "        # Merge this dictionary with the existing metrics for the class\n",
    "        class_dict.update(report[class_label])\n",
    "\n",
    "        # Update the main report dictionary\n",
    "        updated_report[class_label] = class_dict\n",
    "\n",
    "    return updated_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "pos_weight = None\n",
    "if BALANCED:\n",
    "    # Compute weights for loss function\n",
    "    num_labels = len(training_set[0]['targets'])\n",
    "    pos_num = torch.zeros(num_labels).to(device)\n",
    "    for _, data in enumerate(training_loader, 0):\n",
    "        targets = data['targets'].to(device)\n",
    "        pos_num += torch.sum(targets, axis=0)\n",
    "    nobs = len(training_loader.dataset)\n",
    "    pos_weight = (nobs - pos_num) / pos_num\n",
    "\n",
    "    model.model_name += \"_BCE-Balanced\"\n",
    "\n",
    "loss_fn = torch.nn.BCEWithLogitsLoss(pos_weight=pos_weight)  # compute weighted loss for unbalanced dataset\n",
    "optimizer = torch.optim.Adam(params =  model.parameters(), lr=LEARNING_RATE)\n",
    "metrics_dict = {\n",
    "    \"Accuracy\": metrics.accuracy_score,\n",
    "    \"F1 Micro Score\": lambda y_true, y_pred: metrics.f1_score(y_true, y_pred, average='micro', zero_division=0),\n",
    "    \"F1 Macro Score\": lambda y_true, y_pred: metrics.f1_score(y_true, y_pred, average='macro', zero_division=0)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_weight = None\n",
    "if BALANCED:\n",
    "    # Compute weights for loss function\n",
    "    num_labels = len(training_set[0]['targets'])\n",
    "    pos_num = torch.zeros(num_labels).to(device)\n",
    "    for _, data in enumerate(training_loader, 0):\n",
    "        targets = data['targets'].to(device)\n",
    "        pos_num += torch.sum(targets, axis=0)\n",
    "    nobs = len(training_loader.dataset)\n",
    "    pos_weight = (nobs - pos_num) / pos_num\n",
    "\n",
    "    model.model_name += \"_BCE-Balanced\"\n",
    "\n",
    "loss_fn = torch.nn.BCEWithLogitsLoss(pos_weight=pos_weight)  # compute weighted loss for unbalanced dataset\n",
    "optimizer = torch.optim.Adam(params =  model.parameters(), lr=LEARNING_RATE)\n",
    "metrics_dict = {\"Custom Classifcation Report\": lambda y_true, y_pred: custom_classification_report(y_true, y_pred)\n",
    "    # \"Binary Accuracy Macro\": lambda outputs, targets: binary_accuracy_averaged(targets, outputs, threshold=0.5),\n",
    "    # \"Binary Accuracy per Class\": binary_accuracy_per_label,\n",
    "    # \"F1 Score Micro\": lambda y_true, y_pred: metrics.f1_score(y_true, y_pred, average='micro', zero_division=1),\n",
    "    # \"F1 Score Macro\": lambda y_true, y_pred: metrics.f1_score(y_true, y_pred, average='macro', zero_division=1),\n",
    "    # \"F1 Scores per Class\": lambda y_true, y_pred: metrics.f1_score(y_true, y_pred, average=None, zero_division=1)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, epoch, directory='model_save', model_name=None):\n",
    "    \"\"\"\n",
    "    Saves the model state.\n",
    "\n",
    "    Args:\n",
    "    model (torch.nn.Module): The model to save.\n",
    "    epoch (int): The current epoch number.\n",
    "    file_path (str): Base directory to save the models.\n",
    "    \"\"\"\n",
    "    if model_name is None:\n",
    "        model_name = model.model_name\n",
    "\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "    \n",
    "    file_path = os.path.join(directory, f\"{model_name}_epoch_{epoch}.pth\")\n",
    "\n",
    "    torch.save(model.state_dict(), file_path)\n",
    "    print(f'Model saved at {file_path}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model, directory='model_save', model_name=None, epoch=None):\n",
    "    \"\"\"\n",
    "    Loads the model state.\n",
    "\n",
    "    Args:\n",
    "    model (torch.nn.Module): The model to load state into.\n",
    "    file_path (str): Path to the saved model file.\n",
    "    \"\"\"\n",
    "    if model_name is None:\n",
    "        model_name = model.model_name\n",
    "\n",
    "    if epoch is None:\n",
    "        epoch = find_last_saved_epoch(directory, model_name)\n",
    "        if epoch == -1:\n",
    "            print(\"No saved model found.\")\n",
    "            return\n",
    "    \n",
    "    file_path = os.path.join(directory, f\"{model_name}_epoch_{epoch}.pth\")\n",
    "    if not os.path.exists(file_path):\n",
    "        print(f\"No model file found at {file_path}\")\n",
    "        return\n",
    "\n",
    "    model.load_state_dict(torch.load(file_path))\n",
    "    model.to(device)\n",
    "    print(f'Model loaded from {file_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_last_saved_epoch(directory='model_save', model_name=None):\n",
    "    \"\"\"\n",
    "    Finds the last saved epoch number in the specified directory.\n",
    "\n",
    "    Args:\n",
    "    file_path (str): The directory where models are saved.\n",
    "\n",
    "    Returns:\n",
    "    int: The last saved epoch number. Returns -1 if no saved model is found.\n",
    "    \"\"\"\n",
    "    if model_name is None:\n",
    "        model_name = model.model_name\n",
    "\n",
    "    # Check if the directory exists, and create it if it doesn't\n",
    "    if not os.path.exists(directory):\n",
    "        return -1\n",
    "\n",
    "    saved_epochs = []\n",
    "    for filename in os.listdir(directory):\n",
    "        if model_name is None or filename == model_name:\n",
    "            parts = filename.replace('.pth', '').split('_')\n",
    "            if parts[-2] == 'epoch':\n",
    "                try:\n",
    "                    saved_epochs.append(int(parts[-1]))\n",
    "                except ValueError:\n",
    "                    pass\n",
    "    \n",
    "    return max(saved_epochs, default=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_batch(model, batch_data, device, loss_fn, mode, optimizer=None, accumulate_gradients=False):\n",
    "    ids = batch_data['ids'].to(device, dtype=torch.long)\n",
    "    mask = batch_data['mask'].to(device, dtype=torch.long)\n",
    "    token_type_ids = batch_data['token_type_ids'].to(device, dtype=torch.long)\n",
    "    targets = batch_data['targets'].to(device, dtype=torch.float)\n",
    "\n",
    "    if mode == 'train':\n",
    "        outputs = model(ids, mask, token_type_ids)\n",
    "        loss = loss_fn(outputs, targets)\n",
    "        loss.backward()\n",
    "        if not accumulate_gradients:\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "    else:\n",
    "        with torch.no_grad():\n",
    "            outputs = model(ids, mask, token_type_ids)\n",
    "            loss = loss_fn(outputs, targets)\n",
    "\n",
    "    return outputs, targets, loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(metrics_dict, targets, outputs):\n",
    "    return {metric_name: metric_fn(targets, outputs) for metric_name, metric_fn in metrics_dict.items()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(metrics_dict, targets, outputs, is_logit=True, thresholds=0.5, percentile=None):\n",
    "    results = {}\n",
    "    labels = ANOMALY_LABELS\n",
    "    if is_logit:\n",
    "        outputs = torch.sigmoid(outputs)\n",
    "\n",
    "    if thresholds is None:\n",
    "        thresholds = 0.5\n",
    "    # Calculate percentile is specified\n",
    "    if percentile is not None:\n",
    "        thresholds = []\n",
    "        for i in range(outputs.shape[1]):  # Iterate over each label\n",
    "            label_scores = outputs[:, i].detach().cpu().numpy()\n",
    "            threshold = np.percentile(label_scores, percentile)\n",
    "            thresholds.append(threshold)\n",
    "        thresholds = np.array(thresholds)\n",
    "\n",
    "    # Apply thresholds to outputs\n",
    "    outputs = (outputs >= torch.tensor(thresholds, device=outputs.device)).float()\n",
    "\n",
    "    for metric_name, metric_fn in metrics_dict.items():\n",
    "        if metric_name in [\"F1 Scores per Class\", \"Binary Accuracy per Class\"]:\n",
    "            metric_scores = metric_fn(targets.cpu(), outputs.cpu())  # Assuming targets and outputs are tensors\n",
    "            for i, score in enumerate(metric_scores):\n",
    "                label = labels[i] if i < len(labels) else f\"Class {i}\"\n",
    "                results[f\"{metric_name} - {label}\"] = score\n",
    "        else:\n",
    "            results[metric_name] = metric_fn(targets.cpu(), outputs.cpu())\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_value(val):\n",
    "    \"\"\"Helper function to format the value for printing.\"\"\"\n",
    "    if isinstance(val, (float, np.float16, np.float32, np.float64)):\n",
    "        return f\"{val:.4f}\"\n",
    "    elif isinstance(val, torch.Tensor) and val.dtype in [torch.float16, torch.float32, torch.float64]:\n",
    "        return f\"{val.item():.4f}\"\n",
    "    else:\n",
    "        return val\n",
    "\n",
    "def print_metrics_results(metrics_results):\n",
    "    # First, print scalar values and simple dictionaries\n",
    "    for metric, value in metrics_results.items():\n",
    "        if isinstance(value, dict) and not any(isinstance(v, dict) for v in value.values()):\n",
    "            # Print simple dictionaries on a single line\n",
    "            dict_values = \", \".join([f\"{k}: {format_value(v)}\" for k, v in value.items()])\n",
    "            print(f\"{metric}: {dict_values}\")\n",
    "        elif not isinstance(value, dict):\n",
    "            # Print scalar values\n",
    "            print(f\"{metric}: {format_value(value)}\")\n",
    "\n",
    "    # Then, print nested dictionaries\n",
    "    for metric, value in metrics_results.items():\n",
    "        if isinstance(value, dict) and any(isinstance(v, dict) for v in value.values()):\n",
    "            # Print nested dictionaries\n",
    "            print(f\"\\n{metric}:\")\n",
    "            # Find the longest key length for formatting\n",
    "            max_key_length = max(len(str(k)) for k in value.keys())\n",
    "            for sub_key, sub_dict in value.items():\n",
    "                formatted_key = f\"{sub_key}:\".ljust(max_key_length + 2)\n",
    "                dict_values = \", \".join([f\"{k}: {format_value(v)}\" for k, v in sub_dict.items()])\n",
    "                print(f\"  {formatted_key} {dict_values}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_batch_results(mode, epoch, batch, dataset_size, loss, start_time, batch_start_time, batch_size):\n",
    "    current_time = time.time()\n",
    "    elapsed_time = current_time - start_time\n",
    "    batch_time_ms = (current_time - batch_start_time) * 1000\n",
    "\n",
    "    current = (batch + 1) * batch_size\n",
    "    epoch_str = f\"Epoch: {epoch+1}, \" if epoch is not None else \"\"\n",
    "    \n",
    "    print(f\"\\r{mode.capitalize()} - {epoch_str}Batch: {batch+1} [{current:>5d}/{dataset_size:>5d}], \"\n",
    "          f\"Time: {elapsed_time:.0f}s {batch_time_ms:.0f}ms/step, Loss: {loss:>7f}\", end=\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_batches(mode, model, loader, device, loss_fn, optimizer=None, epoch=None, accumulation_steps=None):\n",
    "    total_loss = 0.0\n",
    "    all_targets = []\n",
    "    all_outputs = []\n",
    "    start_time = time.time()\n",
    "\n",
    "    for batch, data in enumerate(loader, 0):\n",
    "        batch_start_time = time.time()\n",
    "        \n",
    "        logits, targets, loss = process_batch(model, data, device, loss_fn, mode, optimizer)\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        if mode == 'train':\n",
    "            if accumulation_steps is not None and (batch + 1) % accumulation_steps == 0:\n",
    "                optimizer.step()\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "        # Detach from the (gradient) computation graph to save on memory\n",
    "        all_outputs.append(logits.detach())\n",
    "        all_targets.append(targets.detach())\n",
    "\n",
    "        batch_size = targets.shape[0]\n",
    "        print_batch_results(mode, epoch, batch, len(loader.dataset), loss.item(), start_time, batch_start_time, batch_size)\n",
    "\n",
    "    if mode == 'train' and optimizer is not None and accumulation_steps is not None:\n",
    "        # Ensure any remaining gradients are applied\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "    \n",
    "    all_outputs = torch.cat(all_outputs, dim=0)\n",
    "    all_targets = torch.cat(all_targets, dim=0)\n",
    "\n",
    "    print()\n",
    "    avg_loss = total_loss / len(loader)\n",
    "    return avg_loss, all_outputs, all_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, validation_loader, loss_fn, metrics_dict, device, hyperparameters=None):\n",
    "    model.eval()\n",
    "    avg_val_loss, val_outputs, val_targets = process_batches('evaluate', model, validation_loader, device, loss_fn)\n",
    "\n",
    "    # Set default values\n",
    "    thresholds = None\n",
    "    percentile = None\n",
    "\n",
    "    # Update values based on hyperparameters if provided\n",
    "    if hyperparameters:\n",
    "        thresholds = hyperparameters.get(\"thresholds\", thresholds)\n",
    "        percentile = hyperparameters.get(\"percentile\", percentile)\n",
    "\n",
    "    metrics_results = calculate_metrics(metrics_dict, val_targets, val_outputs, thresholds=thresholds, percentile=percentile)\n",
    "\n",
    "    print(f\"Evaluation Results:\")\n",
    "    print(f\"Average Loss: {avg_val_loss:.4f}\")\n",
    "    print_metrics_results(metrics_results)\n",
    "\n",
    "    return avg_val_loss, metrics_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, epoch, training_loader, validation_loader, optimizer, loss_fn, metrics_dict, device, accumulation_steps=1):\n",
    "    print(f\"Training Epoch {epoch + 1}\")\n",
    "\n",
    "    # Training phase\n",
    "    model.train()\n",
    "    if optimizer is not None:\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "    avg_train_loss, train_outputs, train_targets = process_batches('train', model, training_loader, device, loss_fn, optimizer, epoch, accumulation_steps)\n",
    "\n",
    "    metrics_results = calculate_metrics(metrics_dict, train_targets, train_outputs)\n",
    "\n",
    "    print(f\"Train Results:\")\n",
    "    print(f\"Average Training Loss for Epoch {epoch + 1}: {avg_train_loss:.4f}\")\n",
    "    print_metrics_results(metrics_results)\n",
    "\n",
    "    # Validation phase\n",
    "    if validation_loader is not None:\n",
    "        avg_val_loss, val_metrics_results = evaluate(model, validation_loader, loss_fn, metrics_dict, device)\n",
    "    else:\n",
    "        avg_val_loss = None\n",
    "        val_metrics_results = {}\n",
    "\n",
    "    return avg_train_loss, avg_val_loss, val_metrics_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NASA-AIML_MIKA_SafeAeroBERT_Unfrozen[8, 9, 10, 11]_BCE-Balanced'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.model_name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No saved model found. Starting training from the beginning.\n",
      "Training Epoch 1\n",
      "Train - Epoch: 1, Batch: 20 [  640/97417], Time: 112s 5555ms/step, Loss: 0.560862, Accuracy: 0.0625, F1 Micro Score: 0.4000, F1 Macro Score: 0.0490"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/ensai/exercises-shell/Safran-Project/aviation-classification.ipynb Cell 27\u001b[0m line \u001b[0;36m1\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/ensai/exercises-shell/Safran-Project/aviation-classification.ipynb#X35sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mNo saved model found. Starting training from the beginning.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/ensai/exercises-shell/Safran-Project/aviation-classification.ipynb#X35sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(start_epoch, EPOCHS):\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/ensai/exercises-shell/Safran-Project/aviation-classification.ipynb#X35sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m     train_loss, val_loss, val_metrics \u001b[39m=\u001b[39m train(model, epoch, training_loader, testing_loader, optimizer, loss_fn, metrics_dict, device)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/ensai/exercises-shell/Safran-Project/aviation-classification.ipynb#X35sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m     save_model(model, epoch, directory\u001b[39m=\u001b[39mMODEL_DIRECTORY, model_name\u001b[39m=\u001b[39mMODEL_NAME)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/ensai/exercises-shell/Safran-Project/aviation-classification.ipynb#X35sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m     \u001b[39m# Additional epoch-level processing if needed\u001b[39;00m\n",
      "\u001b[1;32m/home/ensai/exercises-shell/Safran-Project/aviation-classification.ipynb Cell 27\u001b[0m line \u001b[0;36m5\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/ensai/exercises-shell/Safran-Project/aviation-classification.ipynb#X35sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mTraining Epoch \u001b[39m\u001b[39m{\u001b[39;00mepoch\u001b[39m \u001b[39m\u001b[39m+\u001b[39m\u001b[39m \u001b[39m\u001b[39m1\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/ensai/exercises-shell/Safran-Project/aviation-classification.ipynb#X35sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39m# Training phase\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/ensai/exercises-shell/Safran-Project/aviation-classification.ipynb#X35sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m avg_train_loss, _, _ \u001b[39m=\u001b[39m process_batches(\u001b[39m'\u001b[39;49m\u001b[39mtrain\u001b[39;49m\u001b[39m'\u001b[39;49m, model, training_loader, device, loss_fn, metrics_dict, optimizer, epoch\u001b[39m=\u001b[39;49mepoch)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/ensai/exercises-shell/Safran-Project/aviation-classification.ipynb#X35sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mAverage Training Loss for Epoch \u001b[39m\u001b[39m{\u001b[39;00mepoch\u001b[39m \u001b[39m\u001b[39m+\u001b[39m\u001b[39m \u001b[39m\u001b[39m1\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m: \u001b[39m\u001b[39m{\u001b[39;00mavg_train_loss\u001b[39m:\u001b[39;00m\u001b[39m.4f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/ensai/exercises-shell/Safran-Project/aviation-classification.ipynb#X35sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39m# Validation phase\u001b[39;00m\n",
      "\u001b[1;32m/home/ensai/exercises-shell/Safran-Project/aviation-classification.ipynb Cell 27\u001b[0m line \u001b[0;36m1\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/ensai/exercises-shell/Safran-Project/aviation-classification.ipynb#X35sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m batch_start_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/ensai/exercises-shell/Safran-Project/aviation-classification.ipynb#X35sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m outputs, targets, loss \u001b[39m=\u001b[39m process_batch(model, data, device, loss_fn, mode, optimizer)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/ensai/exercises-shell/Safran-Project/aviation-classification.ipynb#X35sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m total_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m loss\u001b[39m.\u001b[39;49mitem()\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/ensai/exercises-shell/Safran-Project/aviation-classification.ipynb#X35sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m outputs_binary \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39msigmoid(outputs)\u001b[39m.\u001b[39mcpu()\u001b[39m.\u001b[39mdetach()\u001b[39m.\u001b[39mnumpy() \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39m0.5\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/ensai/exercises-shell/Safran-Project/aviation-classification.ipynb#X35sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m targets \u001b[39m=\u001b[39m targets\u001b[39m.\u001b[39mcpu()\u001b[39m.\u001b[39mdetach()\u001b[39m.\u001b[39mnumpy()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "last_saved_epoch = find_last_saved_epoch(directory=MODEL_DIRECTORY, model_name=MODEL_NAME)\n",
    "\n",
    "start_epoch = last_saved_epoch + 1 if last_saved_epoch != -1 else 0\n",
    "if last_saved_epoch != -1:\n",
    "    load_model(model, directory=MODEL_DIRECTORY, model_name=MODEL_NAME, epoch=last_saved_epoch)\n",
    "    print(f\"Loaded model training from epoch {start_epoch}\")\n",
    "else:\n",
    "    print(\"No saved model found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resuming training from epoch 1\n",
      "Training Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train - Epoch: 1, Batch: 3031 [78806/96986], Time: 1546s 404ms/step, Loss: 0.599502\n",
      "Train Results:\n",
      "Average Training Loss for Epoch 1: 0.5714\n",
      "\n",
      "Custom Classifcation Report:\n",
      "  Deviation / Discrepancy - Procedural:  binary_accuracy: 0.7017, precision: 0.7904, recall: 0.6860, f1-score: 0.7345, support: 58337.0000\n",
      "  Aircraft Equipment:                    binary_accuracy: 0.8489, precision: 0.7715, recall: 0.8718, f1-score: 0.8186, support: 37932.0000\n",
      "  Conflict:                              binary_accuracy: 0.8692, precision: 0.5867, recall: 0.9095, f1-score: 0.7133, support: 17342.0000\n",
      "  Inflight Event / Encounter:            binary_accuracy: 0.8129, precision: 0.4833, recall: 0.7895, f1-score: 0.5996, support: 17203.0000\n",
      "  ATC Issue:                             binary_accuracy: 0.8069, precision: 0.4528, recall: 0.9072, f1-score: 0.6041, support: 15751.0000\n",
      "  Deviation - Altitude:                  binary_accuracy: 0.8486, precision: 0.3683, recall: 0.9151, f1-score: 0.5252, support: 8876.0000\n",
      "  Deviation - Track / Heading:           binary_accuracy: 0.8339, precision: 0.3261, recall: 0.8866, f1-score: 0.4769, support: 8279.0000\n",
      "  Ground Event / Encounter:              binary_accuracy: 0.8617, precision: 0.3363, recall: 0.8494, f1-score: 0.4818, support: 7342.0000\n",
      "  Flight Deck / Cabin / Aircraft Event:  binary_accuracy: 0.8967, precision: 0.4058, recall: 0.8641, f1-score: 0.5522, support: 7147.0000\n",
      "  Ground Incursion:                      binary_accuracy: 0.9125, precision: 0.3762, recall: 0.9358, f1-score: 0.5366, support: 5249.0000\n",
      "  Airspace Violation:                    binary_accuracy: 0.8606, precision: 0.2142, recall: 0.8929, f1-score: 0.3455, support: 3997.0000\n",
      "  Deviation - Speed:                     binary_accuracy: 0.8883, precision: 0.1786, recall: 0.8849, f1-score: 0.2972, support: 2588.0000\n",
      "  Ground Excursion:                      binary_accuracy: 0.9095, precision: 0.1900, recall: 0.9411, f1-score: 0.3162, support: 2157.0000\n",
      "  No Specific Anomaly Occurred:          binary_accuracy: 0.8501, precision: 0.0270, recall: 0.8514, f1-score: 0.0523, support: 471.0000\n",
      "  micro avg:                             binary_accuracy: 0.8501, precision: 0.4834, recall: 0.8190, f1-score: 0.6080, support: 192671.0000\n",
      "  macro avg:                             binary_accuracy: 0.8501, precision: 0.3934, recall: 0.8704, f1-score: 0.5038, support: 192671.0000\n",
      "  weighted avg:                          binary_accuracy: 0.8501, precision: 0.6023, recall: 0.8190, f1-score: 0.6636, support: 192671.0000\n",
      "  samples avg:                           binary_accuracy: 0.8501, precision: 0.5626, recall: 0.8197, f1-score: 0.6249, support: 192671.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluate - Batch: 338 [ 7098/10805], Time: 100s 191ms/step, Loss: 0.416931\n",
      "Evaluation Results:\n",
      "Average Loss: 0.5172\n",
      "\n",
      "Custom Classifcation Report:\n",
      "  Deviation / Discrepancy - Procedural:  binary_accuracy: 0.7338, precision: 0.8097, recall: 0.7145, f1-score: 0.7591, support: 6343.0000\n",
      "  Aircraft Equipment:                    binary_accuracy: 0.8634, precision: 0.7830, recall: 0.9140, f1-score: 0.8435, support: 4351.0000\n",
      "  Conflict:                              binary_accuracy: 0.9162, precision: 0.6939, recall: 0.9276, f1-score: 0.7939, support: 1879.0000\n",
      "  Inflight Event / Encounter:            binary_accuracy: 0.8571, precision: 0.6349, recall: 0.8535, f1-score: 0.7282, support: 2423.0000\n",
      "  ATC Issue:                             binary_accuracy: 0.8566, precision: 0.6379, recall: 0.8921, f1-score: 0.7439, support: 2522.0000\n",
      "  Deviation - Altitude:                  binary_accuracy: 0.8529, precision: 0.3726, recall: 0.9532, f1-score: 0.5358, support: 962.0000\n",
      "  Deviation - Track / Heading:           binary_accuracy: 0.8538, precision: 0.3460, recall: 0.9073, f1-score: 0.5009, support: 874.0000\n",
      "  Ground Event / Encounter:              binary_accuracy: 0.9199, precision: 0.5390, recall: 0.7986, f1-score: 0.6436, support: 978.0000\n",
      "  Flight Deck / Cabin / Aircraft Event:  binary_accuracy: 0.9239, precision: 0.5304, recall: 0.8260, f1-score: 0.6460, support: 908.0000\n",
      "  Ground Incursion:                      binary_accuracy: 0.9265, precision: 0.3607, recall: 0.9692, f1-score: 0.5257, support: 454.0000\n",
      "  Airspace Violation:                    binary_accuracy: 0.9308, precision: 0.3393, recall: 0.8892, f1-score: 0.4912, support: 406.0000\n",
      "  Deviation - Speed:                     binary_accuracy: 0.9003, precision: 0.2567, recall: 0.9332, f1-score: 0.4027, support: 389.0000\n",
      "  Ground Excursion:                      binary_accuracy: 0.9572, precision: 0.3847, recall: 0.9625, f1-score: 0.5497, support: 293.0000\n",
      "  No Specific Anomaly Occurred:          binary_accuracy: 0.8307, precision: 0.0402, recall: 0.8539, f1-score: 0.0767, support: 89.0000\n",
      "  micro avg:                             binary_accuracy: 0.8802, precision: 0.5701, recall: 0.8453, f1-score: 0.6810, support: 22871.0000\n",
      "  macro avg:                             binary_accuracy: 0.8802, precision: 0.4806, recall: 0.8853, f1-score: 0.5886, support: 22871.0000\n",
      "  weighted avg:                          binary_accuracy: 0.8802, precision: 0.6638, recall: 0.8453, f1-score: 0.7236, support: 22871.0000\n",
      "  samples avg:                           binary_accuracy: 0.8802, precision: 0.6338, recall: 0.8653, f1-score: 0.6917, support: 22871.0000\n",
      "Model saved at model_save/NASA-AIML_MIKA_SafeAeroBERT_Unfrozen[8, 9, 10, 11]_BCE-Balanced_epoch_0.pth\n",
      "Training Epoch 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train - Epoch: 2, Batch: 2710 [86720/96986], Time: 1404s 546ms/step, Loss: 0.413910"
     ]
    }
   ],
   "source": [
    "if start_epoch < EPOCHS:\n",
    "    print(f\"Resuming training from epoch {start_epoch + 1}\")\n",
    "else:\n",
    "    print(\"No saved model found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resuming training from epoch 1\n",
      "Training Epoch 1\n",
      "Train - Epoch: 1, Batch: 61 [ 1952/96986], Time: 83s 959ms/step, Loss: 0.6018489"
     ]
    }
   ],
   "source": [
    "if start_epoch < EPOCHS:\n",
    "    print(f\"Resuming training from epoch {start_epoch + 1}\")\n",
    "\n",
    "for epoch in range(start_epoch, EPOCHS):\n",
    "    train_loss, val_loss, val_metrics = train(model, epoch, training_loader, testing_loader, optimizer, loss_fn, metrics_dict, device, accumulation_steps=8)\n",
    "    save_model(model, epoch, directory=MODEL_DIRECTORY, model_name=MODEL_NAME)\n",
    "    # Additional epoch-level processing if needed\n",
    "\n",
    "# Testing phase\n",
    "avg_test_loss, test_metrics_results = evaluate(model, testing_loader, loss_fn, metrics_dict, device)\n",
    "print(f\"Test Results:\")\n",
    "print(f\"Average Loss: {avg_test_loss:.4f}\")\n",
    "print_metrics_results(test_metrics_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_thresholds(logits, targets, metrics_dict, num_labels):\n",
    "    best_global_metric = -np.inf\n",
    "    best_thresholds = [0.5] * num_labels\n",
    "\n",
    "    # Iterate over a range of thresholds for each label\n",
    "    for label in range(num_labels):\n",
    "        for threshold in np.linspace(0, 1, 110):  # Example range and step size\n",
    "            temp_thresholds = best_thresholds.copy()\n",
    "            temp_thresholds[label] = threshold\n",
    "            metrics_results = calculate_metrics(metrics_dict, targets, logits, thresholds=temp_thresholds)\n",
    "            current_metric = metrics_results[\"Optimization Metric\"]\n",
    "\n",
    "            if current_metric > best_global_metric:\n",
    "                best_global_metric = current_metric\n",
    "                best_thresholds = temp_thresholds\n",
    "\n",
    "    metrics_results = calculate_metrics(metrics_dict, targets, logits, thresholds=best_thresholds)\n",
    "    return best_thresholds, metrics_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluate - Batch: 5 [  160/10805], Time: 2s 293ms/step, Loss: 0.190116"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluate - Batch: 338 [ 7098/10805], Time: 100s 191ms/step, Loss: 0.131393\n"
     ]
    }
   ],
   "source": [
    "# Run the model to get logits\n",
    "_, logits, targets = process_batches('evaluate', model, testing_loader, device, loss_fn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimized Thresholds: [0.28440366972477066, 0.44036697247706424, 0.6880733944954129, 0.3577981651376147, 0.5, 0.47706422018348627, 0.48623853211009177, 0.3853211009174312, 0.41284403669724773, 0.5321100917431193, 0.3119266055045872, 0.3853211009174312, 0.3944954128440367, 0.06422018348623854]\n",
      "Optimization Metric: 0.7312\n",
      "\n",
      "Custom Classifcation Report:\n",
      "  Deviation / Discrepancy - Procedural:  binary_accuracy: 0.7810, precision: 0.7721, recall: 0.8895, f1-score: 0.8267, support: 6343.0000\n",
      "  Aircraft Equipment:                    binary_accuracy: 0.9139, precision: 0.8901, recall: 0.8970, f1-score: 0.8935, support: 4351.0000\n",
      "  Conflict:                              binary_accuracy: 0.9526, precision: 0.8641, recall: 0.8632, f1-score: 0.8637, support: 1879.0000\n",
      "  Inflight Event / Encounter:            binary_accuracy: 0.9001, precision: 0.7684, recall: 0.7941, f1-score: 0.7810, support: 2423.0000\n",
      "  ATC Issue:                             binary_accuracy: 0.9079, precision: 0.7726, recall: 0.8580, f1-score: 0.8131, support: 2522.0000\n",
      "  Deviation - Altitude:                  binary_accuracy: 0.9550, precision: 0.7761, recall: 0.6954, f1-score: 0.7336, support: 962.0000\n",
      "  Deviation - Track / Heading:           binary_accuracy: 0.9535, precision: 0.7209, recall: 0.6945, f1-score: 0.7075, support: 874.0000\n",
      "  Ground Event / Encounter:              binary_accuracy: 0.9450, precision: 0.7025, recall: 0.6810, f1-score: 0.6916, support: 978.0000\n",
      "  Flight Deck / Cabin / Aircraft Event:  binary_accuracy: 0.9623, precision: 0.8257, recall: 0.6993, f1-score: 0.7573, support: 908.0000\n",
      "  Ground Incursion:                      binary_accuracy: 0.9755, precision: 0.6894, recall: 0.7577, f1-score: 0.7219, support: 454.0000\n",
      "  Airspace Violation:                    binary_accuracy: 0.9758, precision: 0.6799, recall: 0.6749, f1-score: 0.6774, support: 406.0000\n",
      "  Deviation - Speed:                     binary_accuracy: 0.9762, precision: 0.6658, recall: 0.6812, f1-score: 0.6734, support: 389.0000\n",
      "  Ground Excursion:                      binary_accuracy: 0.9888, precision: 0.7774, recall: 0.8225, f1-score: 0.7993, support: 293.0000\n",
      "  No Specific Anomaly Occurred:          binary_accuracy: 0.9798, precision: 0.2081, recall: 0.5169, f1-score: 0.2968, support: 89.0000\n",
      "  micro avg:                             binary_accuracy: 0.9405, precision: 0.7876, recall: 0.8308, f1-score: 0.8086, support: 22871.0000\n",
      "  macro avg:                             binary_accuracy: 0.9405, precision: 0.7224, recall: 0.7518, f1-score: 0.7312, support: 22871.0000\n",
      "  weighted avg:                          binary_accuracy: 0.9405, precision: 0.7919, recall: 0.8308, f1-score: 0.8093, support: 22871.0000\n",
      "  samples avg:                           binary_accuracy: 0.9405, precision: 0.8168, recall: 0.8606, f1-score: 0.8082, support: 22871.0000\n"
     ]
    }
   ],
   "source": [
    "opt_metrics_dict = {\n",
    "    \"Optimization Metric\": lambda y_true, y_pred: metrics.f1_score(y_true, y_pred, average='macro', zero_division=0)\n",
    "}\n",
    "opt_metrics_dict.update(metrics_dict)\n",
    "\n",
    "# Optimize thresholds\n",
    "best_thresholds, metrics_results = optimize_thresholds(logits, targets, opt_metrics_dict, num_labels=len(ANOMALY_LABELS))\n",
    "\n",
    "print(\"Optimized Thresholds:\", best_thresholds)\n",
    "print_metrics_results(metrics_results)\n",
    "\n",
    "# # Use these thresholds in your evaluation\n",
    "# avg_test_loss, test_metrics_results = evaluate(model, testing_loader, loss_fn, metrics_dict, device, hyperparameters=best_thresholds)\n",
    "# print(\"Test Results with Optimized Thresholds:\")\n",
    "# print_metrics_results(test_metrics_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ENSAI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
