{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install kornia\n",
    "# ! pip install kornia[x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing stock ml libraries\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import metrics\n",
    "import transformers\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from transformers import BertTokenizer, BertModel, BertConfig, BertForSequenceClassification\n",
    "from transformers import AutoTokenizer, AutoModel, AutoModelForSequenceClassification\n",
    "from kornia.losses import BinaryFocalLossWithLogits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setting up the device for GPU usage\n",
    "from torch import cuda\n",
    "device = 'cuda' if cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Root label (source = ASRS coding forms) : order = by descending frequency\n",
    "ANOMALY_LABELS = ['Deviation / Discrepancy - Procedural',\n",
    "                    'Aircraft Equipment',\n",
    "                    'Conflict',\n",
    "                    'Inflight Event / Encounter',\n",
    "                    'ATC Issue',\n",
    "                    'Deviation - Altitude',\n",
    "                    'Deviation - Track / Heading',\n",
    "                    'Ground Event / Encounter',\n",
    "                    'Flight Deck / Cabin / Aircraft Event',\n",
    "                    'Ground Incursion',\n",
    "                    'Airspace Violation',\n",
    "                    'Deviation - Speed',\n",
    "                    'Ground Excursion',\n",
    "                    'No Specific Anomaly Occurred']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(path, labels, add_other=False, pp_path=None):\n",
    "    loaded_data = pd.read_pickle(path)[0]\n",
    "\n",
    "    # Drop Anomaly NaN's\n",
    "    loaded_data = loaded_data.dropna(subset=['Anomaly'])#.reset_index(drop=True)\n",
    "\n",
    "    # Convert the 'Anomaly' column to a list of lists\n",
    "    anomaly_series = loaded_data['Anomaly']\n",
    "    anomaly_list = anomaly_series.str.split(';').apply(lambda x: [item.strip() for item in x])\n",
    "\n",
    "    # Initialize a DataFrame to hold the one-hot-encoded anomalies\n",
    "    anomaly_df = pd.DataFrame(index=loaded_data.index)\n",
    "\n",
    "    # Populate the DataFrame with one-hot-encoded columns for each prefix\n",
    "    for prefix in labels:\n",
    "        anomaly_df[prefix] = anomaly_list.apply(lambda anomalies: any(anomaly.startswith(prefix) for anomaly in anomalies)).astype(int)\n",
    "\n",
    "    # Add the 'Other' category\n",
    "    if add_other:\n",
    "        anomaly_df['Other'] = (anomaly_df.sum(axis=1) == 0).astype(int)\n",
    "\n",
    "    # Assign the one-hot-encoded anomalies as a new column 'labels' to 'loaded_data'\n",
    "    loaded_data['labels'] = anomaly_df.apply(lambda row: row.tolist(), axis=1)\n",
    "\n",
    "    # Now, 'loaded_data' is a DataFrame that includes both the 'text' and 'labels' columns\n",
    "    if pp_path is None:\n",
    "        loaded_data['text'] = loaded_data[\"Narrative\"]\n",
    "    else:\n",
    "        loaded_data['text'] = pd.read_pickle(pp_path)\n",
    "\n",
    "    # If you want to create a new DataFrame with just 'text' and 'labels':\n",
    "    final_df = loaded_data[['text', 'labels']]\n",
    "    return final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining some key variables that will be used later on in the training\n",
    "MODEL_NAME = None\n",
    "MODEL_DIRECTORY = \"model_save\"\n",
    "\n",
    "\n",
    "ABBREVIATION = True\n",
    "# ABBREVIATION = False\n",
    "\n",
    "\n",
    "LOSS_TYPE = 'BCE'\n",
    "# LOSS_TYPE = 'BinaryFocal'\n",
    "\n",
    "# BALANCED = False\n",
    "BALANCED = True\n",
    "\n",
    "# LAYERS_TO_UNFREEZE = None\n",
    "LAYERS_TO_UNFREEZE = [8, 9, 10, 11]\n",
    "\n",
    "# ENCODER_NAME = 'bert-base-uncased'\n",
    "ENCODER_NAME = 'NASA-AIML/MIKA_SafeAeroBERT'\n",
    "# ENCODER_NAME = 'allenai/longformer-base-4096'\n",
    "\n",
    "MAX_LEN = 512\n",
    "# MAX_LEN = 1024\n",
    "\n",
    "TRAIN_EFFECTIVE_BATCH_SIZE = 32 # 32 Effective size for NASA\n",
    "TRAIN_BATCH_SIZE = 32\n",
    "ACCUMULATION_STEPS = TRAIN_EFFECTIVE_BATCH_SIZE / TRAIN_BATCH_SIZE\n",
    "VALID_BATCH_SIZE = TRAIN_BATCH_SIZE\n",
    "EPOCHS = 5 # 5 Epochs for NASA\n",
    "LEARNING_RATE = 1e-05 * 2 # 0.00002 Rate for NASA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "drop the NaN values in Anomaly?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACN</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1163382</th>\n",
       "      <td>I pilot flying performing takeoff . During tak...</td>\n",
       "      <td>[1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>893734</th>\n",
       "      <td>We 6 shipments dry ice flight ; cooling fresh ...</td>\n",
       "      <td>[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>991883</th>\n",
       "      <td>I seen lot mistakes every flight since changed...</td>\n",
       "      <td>[1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1590076</th>\n",
       "      <td>It first time flying KEUG I pilot flying . The...</td>\n",
       "      <td>[0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1715282</th>\n",
       "      <td>I writing report bring attention second depart...</td>\n",
       "      <td>[0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>622204</th>\n",
       "      <td>WE WERE En Route IN Lateral Navigation AT FL31...</td>\n",
       "      <td>[1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>622205</th>\n",
       "      <td>CLRED BY Tower Control TO CROSS Runway 8R/26L ...</td>\n",
       "      <td>[0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>661202</th>\n",
       "      <td>WHILE WORKING NUMEROUS CVG AND CMH DEPS AT A C...</td>\n",
       "      <td>[0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>733747</th>\n",
       "      <td>ON MIDNIGHT SHIFT ; Approximately XA00 Local T...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>874642</th>\n",
       "      <td>I working FD/CD ( Flight Data/Clearance Delive...</td>\n",
       "      <td>[1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>96986 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      text  \\\n",
       "ACN                                                          \n",
       "1163382  I pilot flying performing takeoff . During tak...   \n",
       "893734   We 6 shipments dry ice flight ; cooling fresh ...   \n",
       "991883   I seen lot mistakes every flight since changed...   \n",
       "1590076  It first time flying KEUG I pilot flying . The...   \n",
       "1715282  I writing report bring attention second depart...   \n",
       "...                                                    ...   \n",
       "622204   WE WERE En Route IN Lateral Navigation AT FL31...   \n",
       "622205   CLRED BY Tower Control TO CROSS Runway 8R/26L ...   \n",
       "661202   WHILE WORKING NUMEROUS CVG AND CMH DEPS AT A C...   \n",
       "733747   ON MIDNIGHT SHIFT ; Approximately XA00 Local T...   \n",
       "874642   I working FD/CD ( Flight Data/Clearance Delive...   \n",
       "\n",
       "                                             labels  \n",
       "ACN                                                  \n",
       "1163382  [1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]  \n",
       "893734   [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]  \n",
       "991883   [1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0]  \n",
       "1590076  [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]  \n",
       "1715282  [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]  \n",
       "...                                             ...  \n",
       "622204   [1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]  \n",
       "622205   [0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0]  \n",
       "661202   [0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]  \n",
       "733747   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]  \n",
       "874642   [1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0]  \n",
       "\n",
       "[96986 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if ABBREVIATION:\n",
    "    train_df = load_data(\"./data/train_data_final.pkl\", ANOMALY_LABELS, pp_path=\"./data/train_data_processed2.pkl\")\n",
    "else: \n",
    "    train_df = load_data(\"./data/train_data_final.pkl\", ANOMALY_LABELS)\n",
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACN</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1014798</th>\n",
       "      <td>Flying SLC DELTA THREE Area Navigation arrival...</td>\n",
       "      <td>[1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1806744</th>\n",
       "      <td>ORD busy east flow arrival push . The weather ...</td>\n",
       "      <td>[1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1044902</th>\n",
       "      <td>B737-800 vectored Instrument Landing System Ru...</td>\n",
       "      <td>[1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1764093</th>\n",
       "      <td>We 6 mile final tower cleared Cirrus land fron...</td>\n",
       "      <td>[1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1786435</th>\n",
       "      <td>During Climb Leveled 17 ; 000 departure switch...</td>\n",
       "      <td>[1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1310569</th>\n",
       "      <td>FO flying visual approach runway 26 ZZZ . Wind...</td>\n",
       "      <td>[1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1482118</th>\n",
       "      <td>While assembling GE C2 transfer gearbox ; I no...</td>\n",
       "      <td>[1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1565471</th>\n",
       "      <td>Nearing end hot ; bumpy four-hour Instrument F...</td>\n",
       "      <td>[1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>980316</th>\n",
       "      <td>On approach gear went noticed yellow hash mark...</td>\n",
       "      <td>[1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1269392</th>\n",
       "      <td>Approximately 20 minutes Ferry Flight landing ...</td>\n",
       "      <td>[0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10805 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      text  \\\n",
       "ACN                                                          \n",
       "1014798  Flying SLC DELTA THREE Area Navigation arrival...   \n",
       "1806744  ORD busy east flow arrival push . The weather ...   \n",
       "1044902  B737-800 vectored Instrument Landing System Ru...   \n",
       "1764093  We 6 mile final tower cleared Cirrus land fron...   \n",
       "1786435  During Climb Leveled 17 ; 000 departure switch...   \n",
       "...                                                    ...   \n",
       "1310569  FO flying visual approach runway 26 ZZZ . Wind...   \n",
       "1482118  While assembling GE C2 transfer gearbox ; I no...   \n",
       "1565471  Nearing end hot ; bumpy four-hour Instrument F...   \n",
       "980316   On approach gear went noticed yellow hash mark...   \n",
       "1269392  Approximately 20 minutes Ferry Flight landing ...   \n",
       "\n",
       "                                             labels  \n",
       "ACN                                                  \n",
       "1014798  [1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0]  \n",
       "1806744  [1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]  \n",
       "1044902  [1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]  \n",
       "1764093  [1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0]  \n",
       "1786435  [1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]  \n",
       "...                                             ...  \n",
       "1310569  [1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]  \n",
       "1482118  [1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]  \n",
       "1565471  [1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]  \n",
       "980316   [1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]  \n",
       "1269392  [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0]  \n",
       "\n",
       "[10805 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if ABBREVIATION:\n",
    "    test_df = load_data(\"./data/test_data_final.pkl\", ANOMALY_LABELS, pp_path=\"./data/test_data_processed2.pkl\")\n",
    "else: \n",
    "    test_df = load_data(\"./data/test_data_final.pkl\", ANOMALY_LABELS)\n",
    "    \n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "\n",
    "    def __init__(self, dataframe, tokenizer, max_len):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.data = dataframe\n",
    "        self.text = dataframe.text\n",
    "        self.targets = self.data.labels\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.text)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        text = str(self.text.iloc[index])\n",
    "        text = \" \".join(text.split())\n",
    "\n",
    "        inputs = self.tokenizer(\n",
    "            text,\n",
    "            None,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_token_type_ids=True\n",
    "        )\n",
    "        ids = inputs['input_ids']\n",
    "        mask = inputs['attention_mask']\n",
    "        token_type_ids = inputs[\"token_type_ids\"]\n",
    "\n",
    "\n",
    "        return {\n",
    "            'ids': torch.tensor(ids, dtype=torch.long),\n",
    "            'mask': torch.tensor(mask, dtype=torch.long),\n",
    "            'token_type_ids': torch.tensor(token_type_ids, dtype=torch.long),\n",
    "            'targets': torch.tensor(self.targets.iloc[index], dtype=torch.float)\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SequenceClassificationModel(torch.nn.Module):\n",
    "    def __init__(self, model_name='bert-base-uncased', num_labels=15):\n",
    "        super(SequenceClassificationModel, self).__init__()\n",
    "        self.original_name = model_name\n",
    "        self.model_name = model_name.replace(\"/\", \"_\")\n",
    "        self.l1 = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=num_labels)\n",
    "\n",
    "    def forward(self, ids, mask, token_type_ids):\n",
    "        output = self.l1(ids, attention_mask=mask, token_type_ids=token_type_ids)\n",
    "        return output.logits\n",
    "    \n",
    "    def tokenizer(self):\n",
    "        return AutoTokenizer.from_pretrained(self.original_name)\n",
    "    \n",
    "    def _set_layer_trainable(self, layer, trainable):\n",
    "        for param in layer.parameters():\n",
    "            param.requires_grad = trainable\n",
    "\n",
    "    def _find_and_set_encoder_layers(self, module, layer_nums, trainable):\n",
    "        if hasattr(module, 'encoder'):\n",
    "            for layer_num in layer_nums:\n",
    "                try:\n",
    "                    self._set_layer_trainable(module.encoder.layer[layer_num], trainable)\n",
    "                except IndexError:\n",
    "                    print(f\"Layer {layer_num} not found in the encoder.\")\n",
    "            return True\n",
    "        else:\n",
    "            for child in module.children():\n",
    "                if self._find_and_set_encoder_layers(child, layer_nums, trainable):\n",
    "                    return True\n",
    "        return False\n",
    "\n",
    "    def set_trainable_layers(self, layer_nums=None):\n",
    "        if layer_nums is not None:\n",
    "            self.model_name = f'{self.model_name}_Unfrozen{layer_nums}'\n",
    "            \n",
    "        # Freeze all parameters first\n",
    "        for param in self.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        # Unfreeze classifier layers\n",
    "        if hasattr(self.l1, 'classifier'):\n",
    "            self._set_layer_trainable(self.l1.classifier, True)\n",
    "\n",
    "        # Attempt to find and unfreeze encoder layers\n",
    "        if not self._find_and_set_encoder_layers(self.l1, layer_nums or [], True):\n",
    "            print(\"Encoder layers not found in the model.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at NASA-AIML/MIKA_SafeAeroBERT and are newly initialized: ['bert.pooler.dense.bias', 'classifier.bias', 'bert.pooler.dense.weight', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SequenceClassificationModel(\n",
       "  (l1): BertForSequenceClassification(\n",
       "    (bert): BertModel(\n",
       "      (embeddings): BertEmbeddings(\n",
       "        (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "        (position_embeddings): Embedding(512, 768)\n",
       "        (token_type_embeddings): Embedding(2, 768)\n",
       "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (encoder): BertEncoder(\n",
       "        (layer): ModuleList(\n",
       "          (0-11): 12 x BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (pooler): BertPooler(\n",
       "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (activation): Tanh()\n",
       "      )\n",
       "    )\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (classifier): Linear(in_features=768, out_features=14, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_labels = len(test_df.labels.iloc[0])\n",
    "model = SequenceClassificationModel(ENCODER_NAME, num_labels=num_labels)\n",
    "\n",
    "if ABBREVIATION:\n",
    "    model.model_name += '_Abbreviated'\n",
    "model.set_trainable_layers(LAYERS_TO_UNFREEZE)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN Dataset: (96986, 2)\n",
      "TEST Dataset: (10805, 2)\n"
     ]
    }
   ],
   "source": [
    "# Creating the dataset and dataloader for the neural network\n",
    "print(\"TRAIN Dataset: {}\".format(train_df.shape))\n",
    "print(\"TEST Dataset: {}\".format(test_df.shape))\n",
    "\n",
    "tokenizer = model.tokenizer()\n",
    "training_set = CustomDataset(train_df, tokenizer, MAX_LEN)\n",
    "testing_set = CustomDataset(test_df, tokenizer, MAX_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_params = {'batch_size': TRAIN_BATCH_SIZE,\n",
    "                'shuffle': True,\n",
    "                'num_workers': 2\n",
    "                }\n",
    "\n",
    "test_params = {'batch_size': VALID_BATCH_SIZE,\n",
    "                'shuffle': False,\n",
    "                'num_workers': 2\n",
    "                }\n",
    "\n",
    "training_loader = DataLoader(training_set, **train_params)\n",
    "testing_loader = DataLoader(testing_set, **test_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_accuracy_per_label(y_true, y_pred):\n",
    "    correct = y_pred == y_true\n",
    "    accuracy_per_label = correct.float().mean(axis=0)\n",
    "    return accuracy_per_label\n",
    "\n",
    "def binary_accuracy_averaged(y_true, y_pred):\n",
    "    accuracy_per_label = binary_accuracy_per_label(y_true, y_pred)\n",
    "    accuracy_averaged = accuracy_per_label.mean()\n",
    "    return accuracy_averaged\n",
    "\n",
    "def custom_classification_report(y_true, y_pred):\n",
    "    report = metrics.classification_report(y_true, y_pred, output_dict=True, target_names=ANOMALY_LABELS, zero_division=0)\n",
    "    accuracy = binary_accuracy_per_label(y_true, y_pred)\n",
    "    extended_accuracy_new = np.append(accuracy, [accuracy.mean()] * (len(report) - len(accuracy)))\n",
    "\n",
    "    updated_report = {}\n",
    "    for i, class_label in enumerate(report.keys()):\n",
    "        # Create a new dictionary for the class with binary accuracy\n",
    "        class_dict = {'binary_accuracy': extended_accuracy_new[i]}\n",
    "        \n",
    "        # Merge this dictionary with the existing metrics for the class\n",
    "        class_dict.update(report[class_label])\n",
    "\n",
    "        # Update the main report dictionary\n",
    "        updated_report[class_label] = class_dict\n",
    "\n",
    "    return updated_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(model, name='BCE', balance=False, dataset=None, dataloader=None, device='cpu'):\n",
    "    model.model_name += f'_{name}'\n",
    "    pos_weight = None\n",
    "    \n",
    "    if balance:\n",
    "        if dataset is None or dataloader is None:\n",
    "            raise ValueError(\"balance is set to True, but the data is not given\")\n",
    "        \n",
    "        # Compute weights for loss function\n",
    "        num_labels = len(dataset[0]['targets'])\n",
    "        pos_num = torch.zeros(num_labels).to(device)\n",
    "        for _, data in enumerate(dataloader, 0):\n",
    "            targets = data['targets'].to(device)\n",
    "            pos_num += torch.sum(targets, axis=0)\n",
    "        nobs = len(dataloader.dataset)\n",
    "        pos_weight = (nobs - pos_num) / pos_num\n",
    "\n",
    "        model.model_name += \"-Balanced\"\n",
    "    \n",
    "    if name == 'BCE':\n",
    "        return torch.nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
    "    elif name == 'BinaryFocal':\n",
    "        return BinaryFocalLossWithLogits(pos_weight=pos_weight, gamma=0.5, alpha=1, reduction='mean')\n",
    "    else:\n",
    "        raise ValueError(\"loss not known\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "loss_fn = loss(model, LOSS_TYPE, BALANCED, training_set, training_loader, device)\n",
    "optimizer = torch.optim.Adam(params =  model.parameters(), lr=LEARNING_RATE)\n",
    "metrics_dict = {\"Custom Classifcation Report\": lambda y_true, y_pred: custom_classification_report(y_true, y_pred)\n",
    "    # \"Binary Accuracy Macro\": lambda outputs, targets: binary_accuracy_averaged(targets, outputs, threshold=0.5),\n",
    "    # \"Binary Accuracy per Class\": binary_accuracy_per_label,\n",
    "    # \"F1 Score Micro\": lambda y_true, y_pred: metrics.f1_score(y_true, y_pred, average='micro', zero_division=1),\n",
    "    # \"F1 Score Macro\": lambda y_true, y_pred: metrics.f1_score(y_true, y_pred, average='macro', zero_division=1),\n",
    "    # \"F1 Scores per Class\": lambda y_true, y_pred: metrics.f1_score(y_true, y_pred, average=None, zero_division=1)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, epoch, directory='model_save', model_name=None):\n",
    "    \"\"\"\n",
    "    Saves the model state.\n",
    "\n",
    "    Args:\n",
    "    model (torch.nn.Module): The model to save.\n",
    "    epoch (int): The current epoch number.\n",
    "    file_path (str): Base directory to save the models.\n",
    "    \"\"\"\n",
    "    if model_name is None:\n",
    "        model_name = model.model_name\n",
    "\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "    \n",
    "    file_path = os.path.join(directory, f\"{model_name}_epoch_{epoch}.pth\")\n",
    "\n",
    "    torch.save(model.state_dict(), file_path)\n",
    "    print(f'Model saved at {file_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model, directory='model_save', model_name=None, epoch=None):\n",
    "    \"\"\"\n",
    "    Loads the model state.\n",
    "\n",
    "    Args:\n",
    "    model (torch.nn.Module): The model to load state into.\n",
    "    file_path (str): Path to the saved model file.\n",
    "    \"\"\"\n",
    "    if model_name is None:\n",
    "        model_name = model.model_name\n",
    "\n",
    "    if epoch is None:\n",
    "        epoch = find_last_saved_epoch(directory, model_name)\n",
    "        if epoch == -1:\n",
    "            print(\"No saved model found.\")\n",
    "            return\n",
    "    \n",
    "    file_path = os.path.join(directory, f\"{model_name}_epoch_{epoch}.pth\")\n",
    "    if not os.path.exists(file_path):\n",
    "        print(f\"No model file found at {file_path}\")\n",
    "        return\n",
    "\n",
    "    model.load_state_dict(torch.load(file_path))\n",
    "    model.to(device)\n",
    "    print(f'Model loaded from {file_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_last_saved_epoch(directory='model_save', model_name=None):\n",
    "    \"\"\"\n",
    "    Finds the last saved epoch number in the specified directory.\n",
    "\n",
    "    Args:\n",
    "    file_path (str): The directory where models are saved.\n",
    "\n",
    "    Returns:\n",
    "    int: The last saved epoch number. Returns -1 if no saved model is found.\n",
    "    \"\"\"\n",
    "    if model_name is None:\n",
    "        model_name = model.model_name\n",
    "\n",
    "    # Check if the directory exists, and create it if it doesn't\n",
    "    if not os.path.exists(directory):\n",
    "        return -1\n",
    "\n",
    "    saved_epochs = []\n",
    "    for filename in os.listdir(directory):\n",
    "        parts = filename.split('_epoch_')\n",
    "        model_name_file = parts[0]\n",
    "        epoch_number = parts[1].split('.')[0]\n",
    "        if model_name == model_name_file:\n",
    "            saved_epochs.append(int(epoch_number))\n",
    "    \n",
    "    return max(saved_epochs, default=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_batch(model, batch_data, device, loss_fn, mode, optimizer=None, accumulate_gradients=False):\n",
    "    ids = batch_data['ids'].to(device, dtype=torch.long)\n",
    "    mask = batch_data['mask'].to(device, dtype=torch.long)\n",
    "    token_type_ids = batch_data['token_type_ids'].to(device, dtype=torch.long)\n",
    "    targets = batch_data['targets'].to(device, dtype=torch.float)\n",
    "\n",
    "    if mode == 'train':\n",
    "        outputs = model(ids, mask, token_type_ids)\n",
    "        loss = loss_fn(outputs, targets)\n",
    "        loss.backward()\n",
    "        if not accumulate_gradients:\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "    else:\n",
    "        with torch.no_grad():\n",
    "            outputs = model(ids, mask, token_type_ids)\n",
    "            loss = loss_fn(outputs, targets)\n",
    "\n",
    "    return outputs, targets, loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(metrics_dict, targets, outputs, is_logit=True, thresholds=0.5, percentile=None):\n",
    "    results = {}\n",
    "    labels = ANOMALY_LABELS\n",
    "    if is_logit:\n",
    "        outputs = torch.sigmoid(outputs)\n",
    "\n",
    "    if thresholds is None:\n",
    "        thresholds = 0.5\n",
    "    # Calculate percentile is specified\n",
    "    if percentile is not None:\n",
    "        thresholds = []\n",
    "        for i in range(outputs.shape[1]):  # Iterate over each label\n",
    "            label_scores = outputs[:, i].detach().cpu().numpy()\n",
    "            threshold = np.percentile(label_scores, percentile)\n",
    "            thresholds.append(threshold)\n",
    "        thresholds = np.array(thresholds)\n",
    "\n",
    "    # Apply thresholds to outputs\n",
    "    outputs = (outputs >= torch.tensor(thresholds, device=outputs.device)).float()\n",
    "\n",
    "    for metric_name, metric_fn in metrics_dict.items():\n",
    "        if metric_name in [\"F1 Scores per Class\", \"Binary Accuracy per Class\"]:\n",
    "            metric_scores = metric_fn(targets.cpu(), outputs.cpu())  # Assuming targets and outputs are tensors\n",
    "            for i, score in enumerate(metric_scores):\n",
    "                label = labels[i] if i < len(labels) else f\"Class {i}\"\n",
    "                results[f\"{metric_name} - {label}\"] = score\n",
    "        else:\n",
    "            results[metric_name] = metric_fn(targets.cpu(), outputs.cpu())\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_value(val):\n",
    "    \"\"\"Helper function to format the value for printing.\"\"\"\n",
    "    if isinstance(val, (float, np.float16, np.float32, np.float64)):\n",
    "        return f\"{val:.4f}\"\n",
    "    elif isinstance(val, torch.Tensor) and val.dtype in [torch.float16, torch.float32, torch.float64]:\n",
    "        return f\"{val.item():.4f}\"\n",
    "    else:\n",
    "        return val\n",
    "\n",
    "def print_metrics_results(metrics_results):\n",
    "    # First, print scalar values and simple dictionaries\n",
    "    for metric, value in metrics_results.items():\n",
    "        if isinstance(value, dict) and not any(isinstance(v, dict) for v in value.values()):\n",
    "            # Print simple dictionaries on a single line\n",
    "            dict_values = \", \".join([f\"{k}: {format_value(v)}\" for k, v in value.items()])\n",
    "            print(f\"{metric}: {dict_values}\")\n",
    "        elif not isinstance(value, dict):\n",
    "            # Print scalar values\n",
    "            print(f\"{metric}: {format_value(value)}\")\n",
    "\n",
    "    # Then, print nested dictionaries\n",
    "    for metric, value in metrics_results.items():\n",
    "        if isinstance(value, dict) and any(isinstance(v, dict) for v in value.values()):\n",
    "            # Print nested dictionaries\n",
    "            print(f\"\\n{metric}:\")\n",
    "            # Find the longest key length for formatting\n",
    "            max_key_length = max(len(str(k)) for k in value.keys())\n",
    "            for sub_key, sub_dict in value.items():\n",
    "                formatted_key = f\"{sub_key}:\".ljust(max_key_length + 2)\n",
    "                dict_values = \", \".join([f\"{k}: {format_value(v)}\" for k, v in sub_dict.items()])\n",
    "                print(f\"  {formatted_key} {dict_values}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_batch_results(mode, epoch, batch, dataset_size, loss, start_time, batch_start_time, batch_size):\n",
    "    current_time = time.time()\n",
    "    elapsed_time = current_time - start_time\n",
    "    batch_time_ms = (current_time - batch_start_time) * 1000\n",
    "\n",
    "    current = (batch + 1) * batch_size\n",
    "    epoch_str = f\"Epoch: {epoch+1}, \" if epoch is not None else \"\"\n",
    "    \n",
    "    print(f\"\\r{mode.capitalize()} - {epoch_str}Batch: {batch+1} [{current:>5d}/{dataset_size:>5d}], \"\n",
    "          f\"Time: {elapsed_time:.0f}s {batch_time_ms:.0f}ms/step, Loss: {loss:>7f}\", end=\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_batches(mode, model, loader, device, loss_fn, optimizer=None, epoch=None, accumulation_steps=None):\n",
    "    total_loss = 0.0\n",
    "    all_targets = []\n",
    "    all_outputs = []\n",
    "    start_time = time.time()\n",
    "\n",
    "    for batch, data in enumerate(loader, 0):\n",
    "        batch_start_time = time.time()\n",
    "        \n",
    "        logits, targets, loss = process_batch(model, data, device, loss_fn, mode, optimizer)\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        if mode == 'train':\n",
    "            if accumulation_steps is not None and (batch + 1) % accumulation_steps == 0:\n",
    "                optimizer.step()\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "        # Detach from the (gradient) computation graph to save on memory\n",
    "        all_outputs.append(logits.detach())\n",
    "        all_targets.append(targets.detach())\n",
    "\n",
    "        batch_size = targets.shape[0]\n",
    "        print_batch_results(mode, epoch, batch, len(loader.dataset), loss.item(), start_time, batch_start_time, batch_size)\n",
    "\n",
    "    if mode == 'train' and optimizer is not None and accumulation_steps is not None:\n",
    "        # Ensure any remaining gradients are applied\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "    \n",
    "    all_outputs = torch.cat(all_outputs, dim=0)\n",
    "    all_targets = torch.cat(all_targets, dim=0)\n",
    "\n",
    "    print()\n",
    "    avg_loss = total_loss / len(loader)\n",
    "    return avg_loss, all_outputs, all_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, validation_loader, loss_fn, metrics_dict, device, hyperparameters=None):\n",
    "    model.eval()\n",
    "    avg_val_loss, val_outputs, val_targets = process_batches('evaluate', model, validation_loader, device, loss_fn)\n",
    "\n",
    "    # Set default values\n",
    "    thresholds = None\n",
    "    percentile = None\n",
    "\n",
    "    # Update values based on hyperparameters if provided\n",
    "    if hyperparameters:\n",
    "        thresholds = hyperparameters.get(\"thresholds\", thresholds)\n",
    "        percentile = hyperparameters.get(\"percentile\", percentile)\n",
    "\n",
    "    metrics_results = calculate_metrics(metrics_dict, val_targets, val_outputs, thresholds=thresholds, percentile=percentile)\n",
    "\n",
    "    print(f\"Evaluation Results:\")\n",
    "    print(f\"Average Loss: {avg_val_loss:.4f}\")\n",
    "    print_metrics_results(metrics_results)\n",
    "\n",
    "    return avg_val_loss, metrics_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, epoch, training_loader, validation_loader, optimizer, loss_fn, metrics_dict, device, accumulation_steps=1):\n",
    "    print(f\"Training Epoch {epoch + 1}\")\n",
    "\n",
    "    # Training phase\n",
    "    model.train()\n",
    "    if optimizer is not None:\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "    avg_train_loss, train_outputs, train_targets = process_batches('train', model, training_loader, device, loss_fn, optimizer, epoch, accumulation_steps)\n",
    "\n",
    "    metrics_results = calculate_metrics(metrics_dict, train_targets, train_outputs)\n",
    "\n",
    "    print(f\"Train Results:\")\n",
    "    print(f\"Average Training Loss for Epoch {epoch + 1}: {avg_train_loss:.4f}\")\n",
    "    print_metrics_results(metrics_results)\n",
    "\n",
    "    # Validation phase\n",
    "    if validation_loader is not None:\n",
    "        avg_val_loss, val_metrics_results = evaluate(model, validation_loader, loss_fn, metrics_dict, device)\n",
    "    else:\n",
    "        avg_val_loss = None\n",
    "        val_metrics_results = {}\n",
    "\n",
    "    return avg_train_loss, avg_val_loss, val_metrics_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NASA-AIML_MIKA_SafeAeroBERT_Unfrozen[8, 9, 10, 11]_BCE-Balanced'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.model_name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded from model_save/NASA-AIML_MIKA_SafeAeroBERT_Unfrozen[8, 9, 10, 11]_BCE-Balanced_epoch_4.pth\n",
      "Loaded model training from epoch 5\n"
     ]
    }
   ],
   "source": [
    "last_saved_epoch = find_last_saved_epoch(directory=MODEL_DIRECTORY, model_name=MODEL_NAME)\n",
    "\n",
    "start_epoch = last_saved_epoch + 1 if last_saved_epoch != -1 else 0\n",
    "if last_saved_epoch != -1:\n",
    "    load_model(model, directory=MODEL_DIRECTORY, model_name=MODEL_NAME, epoch=last_saved_epoch)\n",
    "    print(f\"Loaded model training from epoch {start_epoch}\")\n",
    "else:\n",
    "    print(\"No saved model found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluate - Batch: 338 [ 7098/10805], Time: 108s 207ms/step, Loss: 0.359812\n",
      "Evaluation Results:\n",
      "Average Loss: 0.4948\n",
      "\n",
      "Custom Classifcation Report:\n",
      "  Deviation / Discrepancy - Procedural:  binary_accuracy: 0.7577, precision: 0.8409, recall: 0.7243, f1-score: 0.7782, support: 6343.0000\n",
      "  Aircraft Equipment:                    binary_accuracy: 0.9036, precision: 0.8701, recall: 0.8940, f1-score: 0.8819, support: 4351.0000\n",
      "  Conflict:                              binary_accuracy: 0.9259, precision: 0.7195, recall: 0.9404, f1-score: 0.8152, support: 1879.0000\n",
      "  Inflight Event / Encounter:            binary_accuracy: 0.8724, precision: 0.6680, recall: 0.8568, f1-score: 0.7507, support: 2423.0000\n",
      "  ATC Issue:                             binary_accuracy: 0.8822, precision: 0.6891, recall: 0.9025, f1-score: 0.7815, support: 2522.0000\n",
      "  Deviation - Altitude:                  binary_accuracy: 0.8909, precision: 0.4457, recall: 0.9252, f1-score: 0.6016, support: 962.0000\n",
      "  Deviation - Track / Heading:           binary_accuracy: 0.8906, precision: 0.4173, recall: 0.8890, f1-score: 0.5680, support: 874.0000\n",
      "  Ground Event / Encounter:              binary_accuracy: 0.8661, precision: 0.3943, recall: 0.8947, f1-score: 0.5474, support: 978.0000\n",
      "  Flight Deck / Cabin / Aircraft Event:  binary_accuracy: 0.9208, precision: 0.5179, recall: 0.8304, f1-score: 0.6379, support: 908.0000\n",
      "  Ground Incursion:                      binary_accuracy: 0.9363, precision: 0.3942, recall: 0.9604, f1-score: 0.5590, support: 454.0000\n",
      "  Airspace Violation:                    binary_accuracy: 0.9272, precision: 0.3276, recall: 0.8916, f1-score: 0.4792, support: 406.0000\n",
      "  Deviation - Speed:                     binary_accuracy: 0.9238, precision: 0.3123, recall: 0.9280, f1-score: 0.4673, support: 389.0000\n",
      "  Ground Excursion:                      binary_accuracy: 0.9509, precision: 0.3538, recall: 0.9829, f1-score: 0.5203, support: 293.0000\n",
      "  No Specific Anomaly Occurred:          binary_accuracy: 0.9236, precision: 0.0769, recall: 0.7528, f1-score: 0.1396, support: 89.0000\n",
      "  micro avg:                             binary_accuracy: 0.8980, precision: 0.6185, recall: 0.8488, f1-score: 0.7156, support: 22871.0000\n",
      "  macro avg:                             binary_accuracy: 0.8980, precision: 0.5020, recall: 0.8838, f1-score: 0.6091, support: 22871.0000\n",
      "  weighted avg:                          binary_accuracy: 0.8980, precision: 0.7005, recall: 0.8488, f1-score: 0.7468, support: 22871.0000\n",
      "  samples avg:                           binary_accuracy: 0.8980, precision: 0.6750, recall: 0.8679, f1-score: 0.7237, support: 22871.0000\n",
      "Test Results:\n",
      "Average Loss: 0.4948\n",
      "\n",
      "Custom Classifcation Report:\n",
      "  Deviation / Discrepancy - Procedural:  binary_accuracy: 0.7577, precision: 0.8409, recall: 0.7243, f1-score: 0.7782, support: 6343.0000\n",
      "  Aircraft Equipment:                    binary_accuracy: 0.9036, precision: 0.8701, recall: 0.8940, f1-score: 0.8819, support: 4351.0000\n",
      "  Conflict:                              binary_accuracy: 0.9259, precision: 0.7195, recall: 0.9404, f1-score: 0.8152, support: 1879.0000\n",
      "  Inflight Event / Encounter:            binary_accuracy: 0.8724, precision: 0.6680, recall: 0.8568, f1-score: 0.7507, support: 2423.0000\n",
      "  ATC Issue:                             binary_accuracy: 0.8822, precision: 0.6891, recall: 0.9025, f1-score: 0.7815, support: 2522.0000\n",
      "  Deviation - Altitude:                  binary_accuracy: 0.8909, precision: 0.4457, recall: 0.9252, f1-score: 0.6016, support: 962.0000\n",
      "  Deviation - Track / Heading:           binary_accuracy: 0.8906, precision: 0.4173, recall: 0.8890, f1-score: 0.5680, support: 874.0000\n",
      "  Ground Event / Encounter:              binary_accuracy: 0.8661, precision: 0.3943, recall: 0.8947, f1-score: 0.5474, support: 978.0000\n",
      "  Flight Deck / Cabin / Aircraft Event:  binary_accuracy: 0.9208, precision: 0.5179, recall: 0.8304, f1-score: 0.6379, support: 908.0000\n",
      "  Ground Incursion:                      binary_accuracy: 0.9363, precision: 0.3942, recall: 0.9604, f1-score: 0.5590, support: 454.0000\n",
      "  Airspace Violation:                    binary_accuracy: 0.9272, precision: 0.3276, recall: 0.8916, f1-score: 0.4792, support: 406.0000\n",
      "  Deviation - Speed:                     binary_accuracy: 0.9238, precision: 0.3123, recall: 0.9280, f1-score: 0.4673, support: 389.0000\n",
      "  Ground Excursion:                      binary_accuracy: 0.9509, precision: 0.3538, recall: 0.9829, f1-score: 0.5203, support: 293.0000\n",
      "  No Specific Anomaly Occurred:          binary_accuracy: 0.9236, precision: 0.0769, recall: 0.7528, f1-score: 0.1396, support: 89.0000\n",
      "  micro avg:                             binary_accuracy: 0.8980, precision: 0.6185, recall: 0.8488, f1-score: 0.7156, support: 22871.0000\n",
      "  macro avg:                             binary_accuracy: 0.8980, precision: 0.5020, recall: 0.8838, f1-score: 0.6091, support: 22871.0000\n",
      "  weighted avg:                          binary_accuracy: 0.8980, precision: 0.7005, recall: 0.8488, f1-score: 0.7468, support: 22871.0000\n",
      "  samples avg:                           binary_accuracy: 0.8980, precision: 0.6750, recall: 0.8679, f1-score: 0.7237, support: 22871.0000\n"
     ]
    }
   ],
   "source": [
    "if start_epoch < EPOCHS:\n",
    "    print(f\"Resuming training from epoch {start_epoch + 1}\")\n",
    "\n",
    "for epoch in range(start_epoch, EPOCHS):\n",
    "    train_loss, val_loss, val_metrics = train(model, epoch, training_loader, testing_loader, optimizer, loss_fn, metrics_dict, device, accumulation_steps=8)\n",
    "    save_model(model, epoch, directory=MODEL_DIRECTORY, model_name=MODEL_NAME)\n",
    "    # Additional epoch-level processing if needed\n",
    "\n",
    "# Testing phase\n",
    "avg_test_loss, test_metrics_results = evaluate(model, testing_loader, loss_fn, metrics_dict, device)\n",
    "print(f\"Test Results:\")\n",
    "print(f\"Average Loss: {avg_test_loss:.4f}\")\n",
    "print_metrics_results(test_metrics_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_thresholds(logits, targets, metrics_dict, num_labels):\n",
    "    best_global_metric = -np.inf\n",
    "    best_thresholds = [0.5] * num_labels\n",
    "\n",
    "    # Iterate over a range of thresholds for each label\n",
    "    for label in range(num_labels):\n",
    "        for threshold in np.linspace(0, 1, 101):  # Example range and step size\n",
    "            temp_thresholds = best_thresholds.copy()\n",
    "            temp_thresholds[label] = threshold\n",
    "            metrics_results = calculate_metrics(metrics_dict, targets, logits, thresholds=temp_thresholds)\n",
    "            current_metric = metrics_results[\"Optimization Metric\"]\n",
    "\n",
    "            if current_metric > best_global_metric:\n",
    "                best_global_metric = current_metric\n",
    "                best_thresholds = temp_thresholds\n",
    "\n",
    "    metrics_results = calculate_metrics(metrics_dict, targets, logits, thresholds=best_thresholds)\n",
    "    return best_thresholds, metrics_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluate - Batch: 338 [ 7098/10805], Time: 108s 201ms/step, Loss: 0.359812\n"
     ]
    }
   ],
   "source": [
    "# Run the model to get logits\n",
    "_, logits, targets = process_batches('evaluate', model, testing_loader, device, loss_fn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_metrics_dict = {\n",
    "    \"Optimization Metric\": lambda y_true, y_pred: metrics.f1_score(y_true, y_pred, average='macro', zero_division=0)\n",
    "}\n",
    "opt_metrics_dict.update(metrics_dict)\n",
    "\n",
    "# Optimize thresholds\n",
    "best_thresholds, metrics_results = optimize_thresholds(logits, targets, opt_metrics_dict, num_labels=len(ANOMALY_LABELS))\n",
    "\n",
    "print(\"Optimized Thresholds:\", best_thresholds)\n",
    "print_metrics_results(metrics_results)\n",
    "\n",
    "# # Use these thresholds in your evaluation\n",
    "# avg_test_loss, test_metrics_results = evaluate(model, testing_loader, loss_fn, metrics_dict, device, hyperparameters=best_thresholds)\n",
    "# print(\"Test Results with Optimized Thresholds:\")\n",
    "# print_metrics_results(test_metrics_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ENSAI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
